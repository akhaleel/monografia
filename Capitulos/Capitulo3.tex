% Capítulo 3
\chapter{Aplicações desenvolvidas e estudo comparativo}
\label{chapter3}

Nesse capítulo, a seção \ref{metodologyOfChoice} se refere a metodologia de escolha das plataformas para processamento de fluxo de eventos em tempo real, utilizadas pelas aplicações desenvolvidas, explicadas na seção \ref{apps}. Por último, na seção \ref{caseStudy}, é realizado um estudo comparativo das ferramentas ESPs escolhidas anteriormente. 

\section{Metodologia de escolha das plataformas para processamento de fluxo de eventos em tempo real}
\label{metodologyOfChoice}

Inicialmente, foi realizada uma pesquisa com a palavra chave "stream processing" e analisados os primeiros artigos (na ordem do resultado e que citavam mais de uma ferramenta) em busca de citações a ferramentas (open source) de processamento de streams em tempo real. Com base nesse resultado, os nomes das plataformas encontradas foram utilizados para buscar a quantidade de referências no Google Scholar (site para publicação de artigos acadêmicos) e Stack Over Flow (site para discussão de assuntos relacionados a desenvolvimento de software). Na Tab. \ref{tab:tableNumberOfMentions}, constam os resultados desse procedimento.

A plataforma Esper mencionada em \cite{InfoQArticle} e \cite{ConfluentArticle}. foi descartada do processo de escolha por ser um componente para CEP, normalmente integrado a ferramentas ESPs, fugindo do escopo desse trabalho \cite{EsperTech}. Sendo assim, continuando a análise, foram também consideradas as características das opções restantes, estudadas superficialmente nos parágrafos seguintes.

\paragraph{Apache Spark Streaming.} Apache Spark Streaming é uma extensão do Spark para processamento de stream, em near real time. Além disso, o Spark possui outros módulos para consultas a banco de dados, grafos, e aprendizado de máquina \cite{Spark}. O processamento de stream é realizado em micro-batching pelo Spark Streaming (um de seus módulos), utilizando uma abstração conhecida como \abrv[DStream -- Discretized Stream]{DStream}, a qual é composta por uma sequências de \abrv[RDD -- Resilient Distributed Dataset]{RDDs (Resilient Distributed Dataset)}, ilustrada na Fig. \ref{fig:dstream}. RDDs abstraem uma coleção de dados distribuídos e manipulados em paralelo. No Spark, também é possível utilizar processamento em batch, independente do módulo que está sendo utilizado \cite{LearningSpark}.

\begin{figure}[!ht]
  \centering
    \includegraphics[width=0.8\textwidth]{Imagens/dstreamImage.png}
  \caption{Ilustração de um DStream}
  {\bf Fonte:} \cite{Spark}
  \label{fig:dstream}
\end{figure}

\paragraph{Apache Flink.} Apache Flink é um plataforma muito semelhante ao Spark. Com suporte a processamento de streams, os quais são definidos por uma abstração conhecida como DataStream, ilustrada na Fig. \ref{fig:flinkProcessingImage}. O processamento em batch é realizado em cima de DataSets, semalhantes as RDDs do Spak. Da mesma forma como o DStream é definido como uma série de RDDS, o DataStream é composto por uma sequência de DataSets. A abstração Sink é utilizada para armazenar e retornar DataSets. Há suporte também para CEP, processamento em grafos, aprendizado de máquina e consulta a banco de dados \cite{Flink}.

\begin{figure}[htb]
  \centering
    \includegraphics[width=0.8\textwidth]{Imagens/flinkProcessingImage.png}
  \caption{Ilustração de um fluxo de processamento no Flink}
  {\bf Fonte:} \cite{FlinkOverView}
  \label{fig:flinkProcessingImage}
\end{figure}

\paragraph{Apache Storm.} Apache Storm é um plataforma para processamento de stream em tempo real. Ao contrário do Spark, tem "one at time" como modelo de processamento de dados. As streams são compostas por tuplas (unidade básica de dados, as quais processadas numa abstração conhecida como Topologia, ilustrada na Fig. \ref{fig:stormTopology}, composta por um \abrv[DAG -- Directed Acyclic Graph]{DAG (Directed Acyclic Graph \cite{GraphTeory})} de spouts e bolts, respectivamente, resposáveis por emitir streams de dados e processá-los \cite{LearningStorm}. 

\paragraph{Apache Samza.} Apache Samza é outra plataforma para processamento de stream em tempo real, utilizando como abstração base o conceito de mensagem (identificadas por offsets, ids), em vez de tupla, ou, DStream. Os streams são separados em partições contendo mensagens ordenadas (acessadas apenas no modo de leitura), sendo processados por jobs responsáveis por ler e emir fluxos. Assim como o Spark, há suporte para processamento em batch, o qual é realizado processando sequências de streams.

\begin{figure}[htb]
  \centering
    \includegraphics[width=0.6\textwidth]{Imagens/samzaPartitionsImage.png}
  \caption{Ilustração de um stream particionado no Samza}
  {\bf Fonte:} \cite{Samza}
  \label{fig:samzaPartitions}
\end{figure}

Após essas breves descrições das plataformas para processamento de eventos em tempo real e da análise realizada do número de citações, o Spark Streaming e Storm foram escolhidas como ferramentas para o trabalho desenvolvido no Cap. \ref{chapter3}. Isso, porque ambas possuem maior número de citações nas fontes pesquisadas, e consequentemente, comunidades maiores, o que pode favorecer melhor documentação, suporte e continuidade desses projetos. 

Sendo assim, como Flink e Samza são semelhantes ao Spark o único critério de diferenciação, superfecialmente, é o tamanho da comunidade e a popularidade que o Spark tem. No demais, o Storm se diferencia com o conceito de topologia, interessante de ser estudado. Devido a isso, o Spark e Storm foram aprofundados no Cap. \ref{chapter2} e utilizados no trabalho a ser apresentado nesse capítulo.

\begin{table}[!htb]	
	\center
		% Título de tabelas sempre aparecem antes da tabela
	\caption{Quantidade de citações a plataformas ESPs por referência}
	\label{tab:tableNumberOfMentions}
	{
		\begin{tabular}{c|c|c|c|c}
			\hline
            {\bf Referência} & {\bf Spark Streaming} & {\bf Storm} & {\bf Flink} & {\bf Samza}\\
			\hline
			\cite{InfoQArticle} & 1 & 1 & 1 & 1\\
			\cite{ConfluentArticle} & 1 & 0 & 0 & 1\\
			\cite{DzoneArticle} & 1 & 1 & 0 & 1\\
			\cite{Datatorrent} & 1 & 1 & 0 & 0\\
			\cite{CakeSolutionsArticle} & 1 & 1 & 0 & 0\\			
			\cite{VenturebeatArticle} & 1 & 1 & 0 & 0\\
			\cite{BravenewgeekArticle} & 1 & 0 & 0 & 1\\
			\cite{GoogleScholar} & 806 & 766 & 171 & 283\\
			\cite{StackOverFlow} & 1541 & 538 & 567 & 87\\
			\hline
			{\bf Total de citações} & 2354 & 1311 & 739 & 374\\
			\hline
		\end{tabular}
	}
	\center{\bf Fonte:} Elaboração própria
\end{table}

\section{Aplicações desenvolvidas}
\label{apps}

Após a escolha das plataformas para processamento de eventos em tempo real, quatro aplicações foram desenvolvidas. A explicada na subseção \ref{webApp}, exibe numa aplicação web um mapa contendo informações sobre as métricas de e-Participação. A subseção \ref{batchApp}, refere-se a aplicação responsável por processar tweets e coletar essas métricas; a da subseção \ref{sparkApp}, por sua vez, usa o Spark Streaming para realizar análise de sentimento de streams de tweets; a referente a subseção \ref{stormApp}, realiza o mesmo procedimento, mas com o Storm. 

\sloppy
\subsection{Aplicação web para visualização das métricas relacionadas a e-Participação}
\label{webApp}

A aplicação web foi desenvolvida utilizando o framework web Django \cite{Django}, devido a sua simplicidade. Há somente uma página, contruída usando HTML, JavaScript e CSS, na qual o mapa para a visualização das métricas é exibido. O mapa, por sua vez, é obtido com o suporte da API MapsJavaScript \cite{GoogleDevelopers} sendo nele sobrepostas camadas do Google Fusion Tables (aplicação web experimental para visualização de dados, coleta e compartilhamento de tabelas \cite{FusionTables}).

As métricas podem ser escolhidas através de uma caixa de seleção (ComboBox), sendo assim, para cada Estado, se sua respectiva média for maior que a nacional a região dele no mapa é sobreposta com uma camada azul, se menor, vermelha. Ainda, clicando num Estado é possível visualizar um painel informativo com os valores das médias, medianas, mínimo, máximo, variância e desvio padrão, assim como a quantidade de tweets, seguidores, e o tempo de existência da conta.

Além disso, há conexão via API com a aplicação responsável por realizar a coleta de tweets e processamento das métricas. O tempo necessário para o levantamento de todas essas informações é em torno de 1h30m, devido aos limites de requisições à API do Twitter, explicado na subseção \ref{batchApp}, e do Fusion Tables, limitado em 30 chamadas por minuto \cite{GoogleDevelopers}. Devido a isso, essa opção somente é habilitada no código quando necessário. 

O código dessa aplicação está disponível no repositório localizado em \cite{GitRepository}, sendo "brazilian\_smart\_cities\_map" o nome do projeto.

\sloppy
\subsection{Aplicação para processamento de tweets e coleta de métricas relacionadas a e-Participação}
\label{batchApp}

O primeiro passo no desenvolvimento dessa aplicação, foi decidir as contas das quais os tweets seriam processados. Como, normalmente, as capitais dos estados tem maior concentração de pessoas, optou-se por fazer um levantamento dos perfis oficiais de suas respectivas prefeituras, para então posteriormente realizar o processamento dos tweets. Sendo assim, a Tab. \ref{tab:tweetAccounts} lista as contas relacionadas as prefeituras municipais das capitais dos vinte e sete estados brasileiros.

Em seguida, foram escolhidas quais métricas dessas contas seriam possíveis e importantes de coletar, tendo como referência \cite{AVisionOfSocialMedia}. Sendo assim, selecionou-se as seguintes, respectivas ao Twitter: média do número de tweets, seguidores, retweets (compartilhamento de um determinado tweet), comentários realizados por usuários, réplicas a tweets e tempo de resposta. As métricas referentes ao número de usuários acompanhando as listas (junções de timelines) do perfil e o total delas existentes foram desconsideras, pois são relacionadas a contas diferentes das em questão.

De acorco com \cite{AVisionOfSocialMedia}, através dessas métricas é possível obter indicadores relacionados ao nível e-Participação. Alguns dos indicadores propostos  pela \abrv[SNR -- Social Network Ratio]{SNR (Social Network Ratio)} para Redes Sociais são: Atividade, ou, audiência estimada; Tamanho, ou, esforço realizado pelo perfil para se comunicar; Visibilidade, ou, número total de menções ao perfil; Interação, ou, capacidade de impacto (viralização) da comunicação \cite{AVisionOfSocialMedia}.

Portando, pode-se mapear a métrica média de seguidores ao indicador Atividade, e a de menções para o de Visibilidade; da mesma forma, as médias sobre tweets, réplicas por dia e tempo de resposta ao indicador Tamanho; por último, as médias de retweets e favoritos ao de Interação. A Fig. \ref{fig:twitterDataAnalysisClassDiagram} exibe o diagrama de classes da aplicação desenvolvida para o processamento de tweets e coleta dessas métricas.

\begin{figure}[!htb]
  \centering
    \includegraphics[width=1.2\textwidth, angle=90]{Imagens/twitterDataAnalysisClassDiagram.png}
  \caption{Diagrama de classes da aplicação desenvolvida para processamento e coleta de métricas relacionadas a e-Participação}
	\begin{flushleft}{\bf Fonte:} Elaboração própria\end{flushleft}
  \label{fig:twitterDataAnalysisClassDiagram}
\end{figure}

A aplicação exibida no diagrama de classes da Fig. \ref{fig:twitterDataAnalysisClassDiagram} foi desenvolvida na linguagem de programação Java, devido a sua praticidade de uso, utilizando o framework para Web services, Apache CXF \cite{ApacheCXF}, para expor dois de seus serviços através de uma REST API. O primeiro deles é exposto pela interface ITweetService, e o segundo pela ISparkService, pelos seguintes endpoints, respectivamente: "$\backslash$tweets" e "$\backslash$metrics", permitindo intregrá-la a aplicação web descrita na subseção \ref{webApp}. 

A classe que implementa a interface ITweetService, é responsável por realizar a coleta dos 3.200 tweets mais recentes (se disponíveis) de cada conta, através do endpoint "statuses/user\_timeline". Tal quantidade é limitada pela API do Twitter, a qual pode ser alcançada por no máximo 180 requisições, num intervalo de 15 minutos, com autenticação via conta de usuário \cite{TwitterDevelopers}.

Outro endpoint utilizado foi "search/tweets", para pesquisar as menções realizadas pelos cidadãos as contas das prefeituras. O limite de coleta é de 100 tweets coletados para cada requisição, sendo possível realizar 180 a cada 15 minutos. Os endpoints da API do Twitter foram acessados com o suporte da biblioteca Twitter4J \cite{Twitter4J}.

Durante a coleta dos tweets, eles são mapeados para as seguintes classes do modelo da aplicação: UserInfo, que contém as informações respectivas ao usuário da conta (número de seguidores, tweets, localização, username e data de criação da conta), e TweetInfo, contendo as relacionadas ao tweet (data de criação, id do tweet de réplica e a qual usuário ele se refere, quantidade de retweets, favoritos, se é menção ou não, e o tempo de resposta calculado). Em seguida, os modelos são persistidos via a interface ITweetsDAO, a qual se comunica com o banco de dados não relacional MongoDB \cite{Mongo}.

Os tweets coletados por essa aplicação são os mais recentes e anteriores a data 18/06/2016 (incluindo-a). Como essa coleta não foi realizada sob um stream de tweets, a interface ISparkService expõe o serviço responsável por realizar o processamento em batch desses tweets, coletando as métricas relacionadas a e-Participação. Sendo assim, cada métrica é recuperada do banco de dados e mepeadas para um RDD de doubles, quando números, ou, de strings, no caso da data.

\begin{figure}[!htb]
  \centering
    \includegraphics[width=0.6\textwidth]{Imagens/sparkDiagramMapToDouble.png}
  \caption{Diagrama do mapeamento entre um Resilient Distributed Dataset de Long para Double}
	\begin{flushleft}{\bf Fonte:} Elaboração própria\end{flushleft}
  \label{fig:sparkDiagramMapToDoble}
\end{figure}

Sendo assim, após recuperar as métricas, é possível mapeá-las para um RDD de doubles, por meio do qual são obtidos os valores relacionados as suas respectivas médias, medianas, variâncias, máximos, mínimos e desvios padrões. As informações sobre datas, como strings, são mapeadas para o valor 1, representando a ocorrência de um tweet nesse dia; compondo uma sequência de pares, que permite obter e mapear as quantidades de tweets por dia a um RDD de doubles. Tais processos de mapeamentos são ilustrados nas Fig. \ref{fig:sparkDiagramMapToDoble} e Fig.  \ref{fig:sparkDiagramMapDateToDouble}.

Por fim, a interface IFusionTable é utilizada para submeter os valores das métricas relacionadas e-Participação a uma Fusion Table \cite{eParticipationMetrics}, via a API do Google Fusion Tables. Os valores dessa tabela são utilizados para criar o mapa contido na aplicação web.

\begin{figure}[!htb]
  \centering
    \includegraphics[width=0.7\textwidth]{Imagens/sparkDiagramMapDateToDouble.png}
  \caption {Diagrama do mapeamento entre um Resilient Distributed Dataset de Datas para suas respectivas frequências em Double}
	\begin{flushleft}{\bf Fonte:} Elaboração própria\end{flushleft}
  \label{fig:sparkDiagramMapDateToDouble}
\end{figure}

O código dessa aplicação está disponível no repositório localizado em \cite{GitRepository}, sendo "twitter-data-analysis" o nome do projeto.

\begin{table}[!htb]	
	\center
		% Título de tabelas sempre aparecem antes da tabela
	\caption{Contas do Twitter relacionadas as prefeituras municipais das capitais dos vinte e sete estados brasileiros}
	\bigskip
	\label{tab:tweetAccounts}
	{
		\begin{tabular}{c|c|c}
			\hline
            {\bf Estado} & {\bf Capital} & {\bf Conta no Twitter}\\
			\hline
			Acre & Rio Branco & PrefRioBranco\\
			Alagoas & Maceió & PrefMaceio\\
			Amapá & Macapá & PMMacapa\\
			Amazonas & Manaus & PrefManaus\\
			Bahia & Salvador & agecomsalvador\\			
			Distrito Federal & Brasília & Gov\_DF\\
			Ceará & Fortaleza & prefeiturapmf\\
			Espírito Santo & Vitória & VitoriaOnLine\\
			Goiás & Goiánia & PrefeituraGy\\
			Maranhão & São Luís & PrefeituraSL\\
			Mato Grosso & Cuiabá & prefeitura\_CBA\\
			Mato Grosso do Sul & Campo Grande & cgnoticias\\
			Minas Gerais & Belo Horizonte & prefeiturabh\\
			Paraná & Curitiba & Curitiba\_PMC\\
			Paraíba & João Pessoa & pmjponline\\
			Pará & Belém & prefeiturabelem\\
			Pernambuco & Recife & prefrecife\\
			Piauí & Teresina & prefeitura\_the\\
			Rio Grande do Norte & Natal & NatalPrefeitura\\
			Rio Grande do Sul & Porto Alegre & Prefeitura\_POA\\
			Rio de Janeiro & Rio de Janeiro & Prefeitura\_Rio\\
			Rondônia & Porto Velho & prefeitura\_pvh\\
			Roraima & Boa Vista & PrefeituraBV\\
			Santa Catarina & Florianópolis & scflorianopolis\\
			Sergipe & Aracaju & PrefeituraAracaju\\
			São Paulo & São Paulo & prefsp\\
			Tocantins & Palmas & cidadepalmasy\\
			\hline
		\end{tabular}
	}
		\begin{flushleft}{\bf Fonte:} Elaboração própria\end{flushleft}
\end{table}

\bigskip
\bigskip
\bigskip
\bigskip

\subsection{Aplicação para processamento de stream de tweets, utilizando Spark Streaming}
\label{sparkApp}

A aplicação que utiliza o Spark Streaming, foi desenvolvida na linguagem de programação Java. No início de sua execução, é criado um contexto de stream no qual é definindo o cluster onde ela será executada e o intervalo de criação de cada RDD. Tais Resilient Distributed Datasets, são compostos ordenadamente em sequência, formando a abstração conhecida como DStream. No nosso caso, cada RDD é criado após 30000ms; sendo compostos pelos tweets coletados filtrando os nomes das conta das prefeituras no Twitter, enumerados na classe KeyWords, ilustrada no diagrama da Fig. \ref{fig:sparkDataAnalysisClassDiagram}.

O processo mencionado anteriormente, executado pela classe SparkStreaming, começa após a inicialização do contexto de stream, sendo os tweets coletados pela classe TwitterUtils (do próprio Spark Streaming). Durante a coleta dos streams de tweets (eventos), cada RDD é mapeado para a classe TweetInfo (do modelo da aplicação), através de uma transformação map. Na sequência, as ações forEachRDD e collect são executadas para inserir os tweets processados no banco de dados não relacional MongoDB, conforme ilustrado na Fig. \ref{fig:sparkDataAnalysisDiagram}.

\begin{figure}[!htb]
  \centering
    \includegraphics[width=0.8\textwidth]{Imagens/sparkDataAnalysisDiagram.png}
  \caption{Fluxo do processamento de dados da aplicação utilizando o Spark Streaming}
	\begin{flushleft}{\bf Fonte:} Elaboração própria\end{flushleft}
  \label{fig:sparkDataAnalysisDiagram}
\end{figure}

A análise de sentimentos do conteúdo contido nos tweets ocorre durante a última parte do mapeamento, sendo antes disso realizados alguns processamentos para facilitar e viabilizar esse procedimento. Portanto, primeiramente, os textos contidos nos tweets são extraídos e formatados para minúsculo. Em seguida, todas as menções são identificadas pelo padrão em que ocorrem no Twitter (@displayname, nome exibido para os demais usuários da Rede Social) e removidas, assim como as referências a endereços de sites.

No Twitter, quando um tweet é compartilhado ele é marcado com a notação "RT", abreviação de retweet, a qual também é removida do texto em processamento. Além disso, alguns símbolos são removidos, tais como: ., ., \!, \%, \#, etc. Sendo esse o conjunto de processamentos realizados para "limpar" inicialmente o texto, após o qual se inicia o processamento de linguagem natural.

Com esse prósito, usou-se a biblioteca OpenNLP \cite{OpenNlp} para a tokenização dos tweets. Após a obtenção dos tokens, outros processamentos foram necesssários para melhorar o desempenho da fase seguinte, como a substituição das palavras normalmente abreviadas (vc - você, msm - mesmo, pq - porque, q - que, n - não, etc) e de expressões (sqn - só que não, kkk, hahaha, rsrsrs para situaões comumente engraçadas) por seus formatos formais, utilizando dicionários previamente construídos. Além disso, foram removidos os tokens contendo "stopwords" (palavras vazias), termo utilizado para as palavras comuns de um certo idioma \cite{DataMining}.

Após a obtenção dos tokens, foram atribuídas a eles tags referentes as suas respectivas classes gramáticais, e, por fim, associadas uma part-of speech para cada tweet, usando os tokens e tags obtidos, finalizando a parte do processamento de linguagem natural. Indo então para a última etapa, que é a da análise de sentimentos, tendo como base para isso os adjetivos presentes em cada tweet.

A análise de sentimentos foi realizada com o suporte do Sentilex (versão 1), que é um léxico de sentimentos para o Português, constituído de 6.321 lemas adjectivais (por convenção, na forma masculina singular) e 25.406 formas flexionadas, contendo como um de seus atributos a polaridade do adjectivo. As polaridade são classificadas em positivo (67\% de precisão), negativo (82\% de precisão), ou, neutro (45\% de precisão), possibilitando estimar o sentimento expresso por um determinado texto \cite{Sentilex}.

Os sentimentos são estimados contabilizando as polaridades presentes em cada tweet e o sentimento expresso pelos emotions (se houver), assim sendo, por exemplo, o emotion "(:" incrementa 1 para a polaridade postiva, e 1 para a negativa caso seja ":(". Também, considera-se a presença de advérbios de negação, os quais modificam o significado do verbo, adjetivo e de outros advérbios \cite{Priberam}, alterando consequentemente a polaridade. Por fim, é realizada uma simples normatização com os somatórios das polaridades positivas e negativas, seguindo o seguinte modelo:
{\begin{center} score = ($\Sigma$ positivo - $\Sigma$ negativo) $\div$  ($\Sigma$ positivo + $\Sigma$ negativo)\end{center}}

Caso o score seja menor do que zero, o tweet é classificado com polaridade negativa, se o seu complemento for maior do que 0.5, tem-se polaridade positiva e se igual a zero, neutra. Sendo assim, as informações sobre a polaridade (sentimento) do tweet, seu id e suas respectivas menções (recuperadas do tweet original) são armazenadas no banco de dados não relacional MongoDB. As polaridades são exibidas no mapa da aplicação web.

O código dessa aplicação está disponível no repositório localizado em \cite{GitRepository}, sendo "spark-data-analysis" o nome do projeto, e seu respectivo diagrama de classe é ilustrado na Fig. \ref{fig:sparkDataAnalysisClassDiagram}

\begin{figure}[!htb]
  \centering
    \includegraphics[width=0.8\textwidth]{Imagens/sparkDataAnalysisClassDiagram.png}
  \caption{Diagrama de classes da aplicação utilizando o Spark Streaming}
	\begin{flushleft}{\bf Fonte:} Elaboração própria\end{flushleft}
  \label{fig:sparkDataAnalysisClassDiagram}
\end{figure}

\subsection{Aplicação para processamento de stream de tweets, utilizando Storm}
\label{stormApp}

A aplicação que utiliza o Storm para o processamento de stream de tweets, foi desenvolvida utilizando a linguagem de programação Java. Nela é construída uma topologia, ilustrada na Fig. \ref{fig:stormTopologyApp}, composta por um Spout (classe Twitter), responsável pela conexão ao Twitter e coleta dos tweets, tendo como filtro o nome das contas das prefeituras no Twitter, utilizando a biblioteca Twitter4J.

\begin{figure}[!htb]
  \centering
    \includegraphics[width=0.8\textwidth]{Imagens/stormTopologyApp.png}
  \caption{Topologia da aplicação utilizando Storm}
	\begin{flushleft}{\bf Fonte:} Elaboração própria\end{flushleft}
  \label{fig:stormTopologyApp}
\end{figure}

Em sequência, há seis bolts, responsáveis pelo processamento (o mesmo realizado pela aplicação Spark) dos tweets coletados. O primeiro deles, classe TweetCleanerBolt, ilustrada na Fig. \ref{fig:stormApplicationClassDiagram}, remove as menções e urls contidas no tweet, após isso os simbolos existentes são removidos pelo bolt Symbols Cleaner.

Após isso, a parte do processamento de linguagem natural é realizado pelos bolts Tokenizer e Tag. Na finalização do processo, o bol SentimentAnalyser calcula a polarização de cada tweet, emitindo-os para o bolt Persisting, responsável pelo armazená-los no banco de dados não relacional MongoDB. Vale ainda mencionar que os resultados de cada bolt são setados na classe TweetStream, do modelo da aplicação, o que foi necessário por nem todos os tipos de dados serem serializáveis, como o caso do UserMentionEntity, da biblioteca Twitter4J.

O código dessa aplicação está disponível no repositório localizado em \cite{GitRepository}, sendo "storm-data-analysis" o nome do projeto

\begin{figure}[!htb]
  \centering
    \includegraphics[width=1.2\textwidth, angle=90]{Imagens/stormApplicationClassDiagram.png}
  \caption{Diagrama de classes da aplicação utilizando o Storm}
	\begin{flushleft}{\bf Fonte:} Elaboração própria\end{flushleft}
  \label{fig:stormApplicationClassDiagram}
\end{figure}

\section{Estudo comparativo}
\label{caseStudy}

Nessa seção, é realizada uma análise comparativa entre o Apache Storm e Spark, sendo a subseção \ref{rtp} sobre o requisito de Processamento de grande volume de dados em tempo real, a \ref{faultTolerance} a respeito de Tolerância a falhas, a \ref{garantiesProcessing} sobre Garantias de processamento, a \ref{scalability} em relação a Escalabilidade e, por fim, a \ref{programmingModel} sobre o modelo de programação de ambas as ferramentas. 

\subsection{Processamento de grande volume de dados em tempo real}
\label{rtp}

Quanto ao requisito de processamento de grande volumes de dados, de acordo com a referência \cite{NrtPresentation}, o Apache Spark pode processar até 670k de registros por segundo e por nó, enquanto que o Storm 155k. Portanto, ambas as ferramentas são capazes de processar grande fluxo de dados.

No entanto, elas se diferenciam no requisito de processamento em tempo real. O Spark tem latência de 0.5­2s \cite{DStream2}, e devido a esse delay de até alguns segundos, é considerado uma ferramenta de Near­ real­ time. O Storm, por outro lado, tem como latência de 1­100ms \cite{DStream}, \cite{DStream2}, sendo por isso um sistema com processamento em tempo real.

Como já mencionado na fundamentação tórica, quanto menor o valor de latência, mais rápido se obtém resposta a um dado evento. Além disso, no quesito de processamento em tempo real, também é importante avaliar o valor de throughput, o qual no Spark é maior em comparação ao do Storm \cite{DStream}, favorecendo para o tempo de processamento ser menor.

Como base no que foi dito anteriormente, nesse quesito o Spark é mais adequado as aplicações desenvolvidas, pois elas estão inseridas num contexto em que a propriedade de throughput tem maior relevância. Isso, devido a quantidade de tweets processados, tanto para análise de sentimento, como o módulo Spark Streaming, quanto para a obtenção das métricas relacionadas a e-Participação.

\subsection{Tolerância a falhas}
\label{faultTolerance}

Discretized Streams (D­Streams) é um modelo de programação para processamento de streams distribuídas, utilizado pelo Spark Streaming, capaz de fornecer tolerância a falhas, através do método parallel recovery \cite{DStream3}. Nesse modelo, a tolerância a falhas é implementada através do conceito lineage, o que permite as informações serem recuperadas paralelamente \cite{DStream4}.

O mecanismo de recuperação via lineage é definido por um grafo acíclico dirigido (DAG), por meio do qual RDDs e D­Streams rastreiam, ao nível das partições RDDs, suas respectivas dependências e operações realizadas sob elas \cite{DStream4}. Sendo assim, os RDDs e D­Streams conseguem "saber" como foram construídos. Podendo, consequentemente, cada nó do cluster reconstruí-­lo paralela e eficientemente em caso de falhas. Especificamente, o processo de recuperação é realizado computando novamente uma determinada partição RDD, re­executando as tasks  que a originaram \cite{DStream4}.

Visando prevenir infinitas re­computações, também são realizados checkpoints num determinado espaço de tempo, com replicações assíncronas de RDDs. Tal procedimento não é necessário para todo o conjunto de dados, pois, como já mencionado, a recuperação executada por nós em paralelo é realizada com demasiada eficiência \cite{DStream4}. 

Todo o processo descrito até aqui é confiável quando a fonte dos dados pode ser lida novamente, no caso do Spark Streaming é necessário haver alguma fonte externa para replicação dos dados \cite{Spark}. Além disso, se o Driver for finalizado, por manter o contexto da aplicação, todo o conteúdo em memória dos executors é perdido \cite{Spark}.  

No Storm, a tolerância a falhas é aplicada a cada um de seus componentes. Por exemplo, se o worker falha, ele é reinicializado pelo Supervisor no próprio nó \cite{LearningStorm}. Caso o nó esteja indisposnível, ou, falhando continuadamente, suas tasks são então atribuídas a outro disponível no cluster, via Nimbus \cite{StormPython}. 

O Nimbus e os supervisors, armazenam seus estados no Zookeeper, podendo ser reinicializados sem perdê-los em caso de falha, se houver falha no Zookeeper, outro pode ser "eleito" para o seu lugar \cite{LearningStorm}. Caso algum supervisor falhe, seus workers são reatribuídos pelo Nimbus a outro supervisor, no entanto, ficando impedido de receberem novas tuplas \cite{StormPython}.

Por sua vez, o Nimbus, dentre suas atribuições, é responsável também por reinicializar as tasks caso uma delas venha a falhar, e se o mesmo acontecer com ele próprio, as tasks em execução não são afetadas, mas novas topologias são impedidas de serem submetidas ao cluster \cite{LearningStorm}, assim como reatribuições \cite{StormPython}.

O modelo de recuperação de falhas do Spark pode ser uma boa escolha caso a aplicação permita perda de dados, em prol de eficiência \cite{DStream3}. Caso contrário, é necessário configurar uma fonte externa para replicação dos dados que estão sendo processados. Em contraste, a arquitetura do Storm, busca possibilitar que seus componentes falhem havendo pouco prejuízo para a aplicação, ainda assim a replicação pode adicionar mais uma camada de confiabilidade. 

Levando em consideração o exposto acima, a aplicação desenvolvida para a coleta de métricas realiza processamento em batch, podendo ter acesso a fonte de dados para coletá-los novamente, em caso de falha. Além disso, a eficiência foi priorizada, não havendo prejuízo ao utilizar o Spark. Para aplicação que realiza análise de sentimentos, processamendo stream de tweets, é mais interessante o suporte a tolerância a falhas do Storm, principalmente devido ao seu longo tempo de execução.

\subsubsection{Garantia de processamento}
\label{garantiesProcessing}

Em adição a subseção anterior, o Spark Streaming e Storm possuem formas diferentes de garantir o processamento de um evento. No Spark Streaminghá a garantia de que todo evento será processado exatamente uma vez (Exactly Once), sem perdas, ou, duplicadas, via parallel recovery, levando em consideração as observações já mencionadas \cite{Spark}.

No Storm, por outro lado, não há suporte ao modelo "Exactly Once", mas sim aos "At Least Once" e "At Most Once". Em ordem, a primeira opção permite que o processamento seja realizado no mínimo uma vez, rastreando se o (a) evento (tupla) foi processado(a) ou não, através de seus IDs e mensagens "ack" (tupla processada), podendo haver duplicatas; o oposto ocorre na segunda alternativa, em que perdas são aceitadas processando os eventos no máximo uma vez \cite{Storm}. 

A prosta do Spark Streaming, nesse aspecto, é mais interessante para o processamento de stream de tweets, por através do "Exactly Once" garantir que a informação será processada uma única vez.

\subsection{Escalabilidade}
\label{scalability}

Quanto ao requisito de escalabilidade, ambos suportam clusterização, portando são escaláveis horizontalmente, sendo o maior cluster Spark conhecido composto por 8.000 nós \cite{Spark}. E, embora não tenha sido encontradas fontes confiáveis divulgando informações sobre o maior cluster Storm existente, sabe­se que ele é capaz de processar um milhão de mensagens com tamanho de 100 byte, por segundo e por nó \cite{Storm}.

\subsection{Modelo de programação}
\label{programmingModel}

Conforme exposto no Cap. \ref{chapter2}, no Spark os RDDs são conjuntos de dados que podem ser manipulados de forma distribuída, sendo possível realizar operações sob eles, gerando novos RDDs, através de transformações, ou, computando-os por meio das ações. O módulo Streaming utiliza essa unidade como base da abstração DStream, conjunto de RDDs representando um stream. Tais conceitos do modelo de programação do Spark podem ser mais difíceis de abstrair, tendo uma classificação de baixo nível, se comparados ao do Storm.

Por outro lado, numa perspectiva alto nível, o Storm propõe o conceito de topologia, composta por Bolts e Spouts. Os Spouts são responsáveis pela entrada dos streams (conjunto de tuplas) da aplicação, processados posteriormente pelos Bolts. Devido a essas abstrações, consequentemente, pode haver maior facilidade em programar utilizando o Storm do que o Spark.