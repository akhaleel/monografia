% Capítulo 3
\chapter{Aplicações desenvolvidas e estudo comparativo}
\label{chapter3}

Nesse capítulo, a seção \ref{metodologyOfChoice} se refere a metodologia de escolha das plataformas para processamento de fluxo de eventos em tempo real, utilizadas pelas aplicações desenvolvidas, explicadas na seção \ref{apps}. Por último, na seção \ref{caseStudy}, é realizado um estudo comparativo das ferramentas ESPs escolhidas anteriormente. 

\section{Metodologia de escolha das plataformas para processamento de fluxo de eventos em tempo real}
\label{metodologyOfChoice}

Inicialmente, foi realizada uma pesquisa com a palavra chave "\textit{stream processing}" e analisados os primeiros artigos (na ordem do resultado e que citavam mais de uma ferramenta) em busca de citações a ferramentas (\textit{Open Source}) de processamento de \textit{streams} em tempo real. Com base nesse resultado, os nomes das plataformas encontradas foram utilizados para buscar a quantidade de referências no Google Scholar (site para publicação de artigos acadêmicos) e Stack Over Flow (site para discussão de assuntos relacionados a desenvolvimento de software). Na Tab. \ref{tab:tableNumberOfMentions}, constam os resultados desse procedimento.

A plataforma Esper mencionada em \cite{InfoQArticle} e \cite{ConfluentArticle} foi descartada do processo de escolha por ser um componente para CEP, normalmente integrado a ferramentas ESPs, fugindo do escopo desse trabalho \cite{EsperTech}. Sendo assim, continuando a análise, foram também consideradas as características das opções restantes, analisadas brevemente nos parágrafos seguintes.

\paragraph{Apache Spark Streaming.} Apache Spark Streaming é um módulo do Spark para processamento de \textit{stream}, em Near Real Time. Além disso, o Spark possui outros módulos para consultas a banco de dados, processamento de dados estruturados, grafos, e aprendizado de máquina \cite{Spark}. O processamento de \textit{stream} é realizado em \textit{micro-batching} pelo Spark Streaming, utilizando uma abstração conhecida como \abrv[DStream -- Discretized Stream]{DStream}, composta por uma sequências de \abrv[RDD -- Resilient Distributed Dataset]{RDDs (\textit{Resilient Distributed Dataset})}, ilustrada na Fig. \ref{fig:dstream}. RDDs abstraem uma coleção de dados distribuídos e manipulados em paralelo. No Spark, também é possível utilizar processamento em \textit{batch}, independente do módulo que está sendo utilizado \cite{LearningSpark}.

\begin{figure}[!ht]
  \centering
    \includegraphics[width=0.8\textwidth]{Imagens/dstreamImage.png}
  \caption{Ilustração de um DStream}
  {\bf Fonte:} \cite{Spark}
  \label{fig:dstream}
\end{figure}

\paragraph{Apache Flink.} Apache Flink é um plataforma muito semelhante ao Spark. Com suporte a processamento de \textit{streams}, definidos por uma abstração conhecida como DataStream, ilustrada na Fig. \ref{fig:flinkProcessingImage}. O processamento em \textit{batch} é realizado em cima de DataSets, semalhantes as RDDs do Spak. Da mesma forma como o DStream é definido como uma série de RDDS, o DataStream é composto por uma sequência de DataSets. A abstração conhecida como Sink, é utilizada para armazenar e retornar DataSets. Há suporte também para CEP, processamento em grafos, aprendizado de máquina e consulta a banco de dados \cite{Flink}.

\begin{figure}[htb]
  \centering
    \includegraphics[width=0.8\textwidth]{Imagens/flinkProcessingImage.png}
  \caption{Ilustração de um fluxo de processamento no Flink}
  {\bf Fonte:} \cite{FlinkOverView}
  \label{fig:flinkProcessingImage}
\end{figure}

\paragraph{Apache Storm.} Apache Storm é um plataforma para processamento de \textit{stream} em tempo real. Ao contrário do Spark, tem "\textit{One At Time}" como modelo de processamento de dados. As \textit{streams} são compostas por tuplas (unidade básica de dados, processadas numa abstração conhecida como Topologia, ilustrada na Fig. \ref{fig:stormTopology}, composta por um \abrv[DAG -- Directed Acyclic Graph]{DAG (\textit{Directed Acyclic Graph} \cite{GraphTeory})} de \textit{spouts} e \textit{bolts}, respectivamente, resposáveis por emitir streams de dados e processá-los \cite{LearningStorm}. 

\paragraph{Apache Samza.} Apache Samza é outra plataforma para processamento de \textit{stream} em tempo real, utilizando como abstração base o conceito de mensagem (identificadas por \textit{offsets}, ou, simplesmente\textit{ids}), em vez de tupla, ou, DStream. Os \textit{streams} são separados em partições contendo mensagens ordenadas (acessadas apenas no modo de leitura), sendo processados por \textit{jobs} responsáveis por ler e emir fluxos. Assim como o Spark, há suporte para processamento em \textit{batch}, realizado processando sequências de \textit{streams}.

\begin{figure}[htb]
  \centering
    \includegraphics[width=0.6\textwidth]{Imagens/samzaPartitionsImage.png}
  \caption{Ilustração de um stream particionado no Samza}
  {\bf Fonte:} \cite{Samza}
  \label{fig:samzaPartitions}
\end{figure}

Após essas breves descrições das plataformas para processamento de eventos em tempo real e da análise realizada do número de citações, o Spark Streaming e Storm foram escolhidas como ferramentas para o trabalho desenvolvido no Cap. \ref{chapter3}. Isso, porque ambas possuem maior número de citações nas fontes pesquisadas, e consequentemente, comunidades maiores, o que pode favorecer melhor documentação, suporte e continuidade desses projetos. 

Além disso, como Flink e Samza são semelhantes ao Spark o único critério de diferenciação, superfecialmente, é o tamanho da comunidade e a popularidade que o Spark tem. No demais, o Storm se diferencia com o conceito de topologia, interessante de ser estudado. Devido a isso, o Spark e Storm foram aprofundados no Cap. \ref{chapter2} e utilizados no desenvolvimento das aplicações a serem apresentadas neste capítulo.

\begin{table}[!htb]	
	\center
		% Título de tabelas sempre aparecem antes da tabela
	\caption{Quantidade de citações a plataformas ESPs por referência}
	\label{tab:tableNumberOfMentions}
	{
		\begin{tabular}{c|c|c|c|c}
			\hline
            {\bf Referência} & {\bf Spark Streaming} & {\bf Storm} & {\bf Flink} & {\bf Samza}\\
			\hline
			\cite{InfoQArticle} & 1 & 1 & 1 & 1\\
			\cite{ConfluentArticle} & 1 & 0 & 0 & 1\\
			\cite{DzoneArticle} & 1 & 1 & 0 & 1\\
			\cite{Datatorrent} & 1 & 1 & 0 & 0\\
			\cite{CakeSolutionsArticle} & 1 & 1 & 0 & 0\\			
			\cite{VenturebeatArticle} & 1 & 1 & 0 & 0\\
			\cite{BravenewgeekArticle} & 1 & 0 & 0 & 1\\
			\cite{GoogleScholar} & 806 & 766 & 171 & 283\\
			\cite{StackOverFlow} & 1541 & 538 & 567 & 87\\
			\hline
			{\bf Total de citações} & 2354 & 1311 & 739 & 374\\
			\hline
		\end{tabular}
	}
	\center{\bf Fonte:} Elaboração própria
\end{table}

\section{Aplicações desenvolvidas}
\label{apps}

Após a escolha das plataformas para processamento de eventos em tempo real, quatro aplicações foram desenvolvidas. A explicada na subseção \ref{webApp}, exibe numa aplicação web um mapa contendo informações sobre as métricas de e-Participação e uma visão da polaridade dos sentimentos contidos nos tweets processados. A subseção \ref{batchApp}, refere-se a aplicação responsável por coletar os tweets e processar as métricas de e-Participação; a da subseção \ref{sparkApp}, por sua vez, usa o Spark Streaming para realizar análise de polaridade dos streams de tweets; e a referente a subseção \ref{stormApp}, realiza o mesmo procedimento, mas com o Storm. 

\sloppy
\subsection{Aplicação web para visualização das métricas relacionadas a e-Participação}
\label{webApp}

A aplicação web foi desenvolvida utilizando o framework web Django \cite{Django}, unicamente devido a sua simplicidade. Nela, há somente uma página contruída usando HTML, JavaScript e CSS, na qual o mapa para a visualização das métricas e polaridades é exibido. O mapa, por sua vez, é obtido com o suporte da API MapsJavaScript \cite{GoogleDevelopers} sendo nele sobrepostas camadas do Google Fusion Tables (aplicação web experimental para visualização de dados, coleta e compartilhamento de tabelas \cite{FusionTables}).

As métricas e polaridades podem ser escolhidas através de uma caixa de seleção (ComboBox), sendo assim, para cada Estado, se sua respectiva média for maior que a nacional a região dele no mapa é sobreposta com uma camada azul, se menor, vermelha. Ainda, clicando num Estado é possível visualizar um painel informativo com os valores das médias, medianas, mínimo, máximo, variância e desvio padrão, assim como a quantidade de tweets, seguidores, e o tempo de existência da conta.

Além disso, há conexão via API com a aplicação responsável por realizar a coleta de \textit{tweets} e processamento das métricas. O tempo necessário para o levantamento de todas essas informações é em torno de 1h30m, devido aos limites de requisições à API do Twitter, explicado na subseção \ref{batchApp}, e do Fusion Tables, limitado em 30 chamadas por minuto \cite{GoogleDevelopers}. Devido a isso, essa opção somente é habilitada no código quando necessário. 

O código dessa aplicação está disponível no repositório localizado em \cite{GitRepository}, sendo "brazilian\_smart\_cities\_map" o nome do projeto.

\sloppy
\subsection{Aplicação para processamento de tweets e coleta de métricas relacionadas a e-Participação}
\label{batchApp}

O primeiro passo no desenvolvimento dessa aplicação, foi decidir as contas (perfis) das quais os \textit{tweets} seriam processados. Como, normalmente, as capitais dos estados tem maior concentração de pessoas, optou-se por fazer um levantamento dos perfis oficiais de suas respectivas prefeituras, para então posteriormente realizar o processamento dos \textit{tweets}. Sendo assim, a Tab. \ref{tab:tweetAccounts} lista as contas relacionadas as prefeituras municipais das capitais dos vinte e sete estados brasileiros.

Em seguida, foram escolhidas quais métricas dessas contas seriam possíveis e importantes de coletar, tendo como referência \cite{AVisionOfSocialMedia}. Sendo assim, selecionou-se os seguintes indicadores, respectivos ao Twitter: média do número de \textit{tweets}, seguidores, \textit{retweets} (compartilhamento de um determinado \textit{tweet}), comentários realizados por usuários, réplicas a \textit{tweets} e tempo de resposta. As métricas referentes ao número de usuários acompanhando as listas (junções de \textit{timelines}) dos perfis e o total delas existentes foram desconsideras, pois são relacionadas a contas diferentes das em questão.

De acorco com \cite{AVisionOfSocialMedia}, através dessas métricas é possível obter indicadores relacionados ao nível e-Participação. Alguns dos indicadores propostos  pela \abrv[SNR -- Social Network Ratio]{SNR (\textit{Social Network Ratio})} para Redes Sociais são: Atividade, ou, audiência estimada; Tamanho, ou, esforço realizado pelo perfil para se comunicar; Visibilidade, ou, número total de menções ao perfil; Interação, ou, capacidade de impacto (viralização) da comunicação \cite{AVisionOfSocialMedia}.

Portando, pode-se mapear a métrica média de seguidores ao indicador Atividade, e a de menções para o de Visibilidade; da mesma forma, as médias sobre tweets, réplicas por dia e tempo de resposta ao indicador Tamanho; por último, as médias de retweets e favoritos ao de Interação. A Fig. \ref{fig:twitterDataAnalysisClassDiagram} exibe o diagrama de classes da aplicação desenvolvida para o processamento de tweets e coleta dessas métricas.

\begin{figure}[!htb]
  \centering
    \includegraphics[width=1.2\textwidth, angle=90]{Imagens/twitterDataAnalysisClassDiagram.png}
  \caption{Diagrama de classes da aplicação desenvolvida para processamento e coleta de métricas relacionadas a e-Participação}
	\begin{flushleft}{\bf Fonte:} Elaboração própria\end{flushleft}
  \label{fig:twitterDataAnalysisClassDiagram}
\end{figure}

A aplicação exibida no diagrama de classes da Fig. \ref{fig:twitterDataAnalysisClassDiagram} foi desenvolvida na linguagem de programação Java, devido a sua praticidade de uso, utilizando o framework para Web Services, Apache CXF \cite{ApacheCXF}, para expor dois de seus serviços através de uma REST API. O primeiro deles é exposto pela interface ITweetService, e o segundo pela ISparkService, pelos seguintes \textit{endpoints}, respectivamente: "$\backslash$tweets" e "$\backslash$metrics", permitindo intregrá-la a aplicação web descrita na subseção \ref{webApp}. 

A classe que implementa a interface ITweetService, é responsável por realizar a coleta dos 3.200 \textit{tweets} mais recentes (se disponíveis) de cada conta, através do \textit{endpoint} "statuses/user\_timeline". Tal quantidade é limitada pela API do Twitter, a qual pode ser alcançada por no máximo 180 requisições, num intervalo de 15 minutos, com autenticação via conta de usuário \cite{TwitterDevelopers}.

Outro endpoint utilizado foi "search/tweets", para pesquisar as menções realizadas pelos cidadãos as contas das prefeituras. O limite de coleta é de 100 tweets coletados para cada requisição, sendo possível realizar 180 a cada 15 minutos. Os endpoints da API do Twitter foram acessados com o suporte da biblioteca Twitter4J \cite{Twitter4J}.

Durante a coleta dos \textit{tweets}, eles são mapeados para as seguintes classes do modelo da aplicação: UserInfo, que contém as informações respectivas ao usuário da conta (número de seguidores, \textit{tweets}, localização, \textit{username} e data de criação da conta), e TweetInfo, contendo as relacionadas ao \textit{tweet} (data de criação, \textit{id} do \textit{tweet} de réplica e a qual usuário ele se refere, quantidade de \textit{retweets}, favoritos, se é menção ou não, e o tempo de resposta calculado). Em seguida, os modelos são persistidos via a interface ITweetsDAO, a qual se comunica com o banco de dados não relacional MongoDB \cite{Mongo}.

Os \textit{tweets} coletados por essa aplicação são os mais recentes e anteriores a data 18/06/2016 (incluindo-a). Como essa coleta não foi realizada sob um \textit{stream} de \textit{tweets}, a interface ISparkService expõe o serviço responsável por realizar o processamento em \textit{batch} desses \textit{tweets}, coletando as métricas relacionadas a e-Participação. Sendo assim, cada métrica é recuperada do banco de dados e mepeadas para um RDD de \textit{doubles}, quando números, ou, de \textit{strings}, no caso da data.

\begin{figure}[!htb]
  \centering
    \includegraphics[width=0.6\textwidth]{Imagens/sparkDiagramMapToDouble.png}
  \caption{Diagrama do mapeamento entre um Resilient Distributed Dataset de Long para Double}
	\begin{flushleft}{\bf Fonte:} Elaboração própria\end{flushleft}
  \label{fig:sparkDiagramMapToDoble}
\end{figure}

Sendo assim, após recuperar as métricas, é possível mapeá-las para um RDD de \textit{doubles}, por meio do qual são obtidos os valores relacionados as suas respectivas médias, medianas, variâncias, máximos, mínimos e desvios padrões. As informações sobre datas, como \textit{strings}, são mapeadas para o valor 1, representando a ocorrência de um \textit{tweet} nesse dia; compondo uma sequência de pares, que permite obter e mapear as quantidades de \textit{tweets} por dia a um RDD de \textit{doubles}. Tais processos de mapeamentos são ilustrados nas Fig. \ref{fig:sparkDiagramMapToDoble} e Fig. \ref{fig:sparkDiagramMapDateToDouble}.

Por fim, a interface IFusionTable é utilizada para submeter os valores das métricas relacionadas e-Participação a uma Fusion Table \cite{eParticipationMetrics}, via a API do Google Fusion Tables. Os valores dessa tabela são utilizados para criar o mapa contido na aplicação web.

\begin{figure}[!htb]
  \centering
    \includegraphics[width=0.7\textwidth]{Imagens/sparkDiagramMapDateToDouble.png}
  \caption {Diagrama do mapeamento entre um Resilient Distributed Dataset de Datas para suas respectivas frequências em Double}
	\begin{flushleft}{\bf Fonte:} Elaboração própria\end{flushleft}
  \label{fig:sparkDiagramMapDateToDouble}
\end{figure}

O código dessa aplicação está disponível no repositório localizado em \cite{GitRepository}, sendo "twitter-data-analysis" o nome do projeto.

\begin{table}[!htb]	
	\center
		% Título de tabelas sempre aparecem antes da tabela
	\caption{Contas do Twitter relacionadas as prefeituras municipais das capitais dos vinte e sete estados brasileiros}
	\bigskip
	\label{tab:tweetAccounts}
	{
		\begin{tabular}{c|c|c}
			\hline
            {\bf Estado} & {\bf Capital} & {\bf Conta no Twitter}\\
			\hline
			Acre & Rio Branco & PrefRioBranco\\
			Alagoas & Maceió & PrefMaceio\\
			Amapá & Macapá & PMMacapa\\
			Amazonas & Manaus & PrefManaus\\
			Bahia & Salvador & agecomsalvador\\			
			Distrito Federal & Brasília & Gov\_DF\\
			Ceará & Fortaleza & prefeiturapmf\\
			Espírito Santo & Vitória & VitoriaOnLine\\
			Goiás & Goiánia & PrefeituraGy\\
			Maranhão & São Luís & PrefeituraSL\\
			Mato Grosso & Cuiabá & prefeitura\_CBA\\
			Mato Grosso do Sul & Campo Grande & cgnoticias\\
			Minas Gerais & Belo Horizonte & prefeiturabh\\
			Paraná & Curitiba & Curitiba\_PMC\\
			Paraíba & João Pessoa & pmjponline\\
			Pará & Belém & prefeiturabelem\\
			Pernambuco & Recife & prefrecife\\
			Piauí & Teresina & prefeitura\_the\\
			Rio Grande do Norte & Natal & NatalPrefeitura\\
			Rio Grande do Sul & Porto Alegre & Prefeitura\_POA\\
			Rio de Janeiro & Rio de Janeiro & Prefeitura\_Rio\\
			Rondônia & Porto Velho & prefeitura\_pvh\\
			Roraima & Boa Vista & PrefeituraBV\\
			Santa Catarina & Florianópolis & scflorianopolis\\
			Sergipe & Aracaju & PrefeituraAracaju\\
			São Paulo & São Paulo & prefsp\\
			Tocantins & Palmas & cidadepalmasy\\
			\hline
		\end{tabular}
	}
		\begin{flushleft}{\bf Fonte:} Elaboração própria\end{flushleft}
\end{table}

\bigskip
\bigskip
\bigskip
\bigskip

\subsection{Aplicação para processamento de stream de tweets, utilizando Spark Streaming}
\label{sparkApp}

A aplicação que utiliza o Spark Streaming, foi desenvolvida na linguagem de programação Java. No início de sua execução, é criado um contexto de \textit{stream} no qual é definindo o \textit{cluster} onde ela será executada e o intervalo de criação de cada RDD. Tais Resilient Distributed Datasets, são compostos ordenadamente em sequência, formando a abstração conhecida como DStream. No nosso caso, cada RDD é criado após 30000ms; sendo compostos pelos \textit{tweets} coletados filtrando os nomes das conta das prefeituras no Twitter, enumerados na classe KeyWords, ilustrada no diagrama da Fig. \ref{fig:sparkDataAnalysisClassDiagram}.

O processo mencionado anteriormente, executado pela classe SparkStreaming, começa após a inicialização do contexto de stream, sendo os \textit{tweets} coletados pela classe TwitterUtils (do próprio Spark Streaming). Durante a coleta dos \textit{streams} de \textit{tweets} (eventos), cada RDD é mapeado para a classe TweetInfo (do modelo da aplicação), através de uma transformação map. Na sequência, as ações forEachRDD e collect são executadas para inserir os \textit{tweets} processados no banco de dados não relacional MongoDB, conforme ilustrado na Fig. \ref{fig:sparkDataAnalysisDiagram}.

\begin{figure}[!htb]
  \centering
    \includegraphics[width=0.8\textwidth]{Imagens/sparkDataAnalysisDiagram.png}
  \caption{Fluxo do processamento de dados da aplicação utilizando o Spark Streaming}
	\begin{flushleft}{\bf Fonte:} Elaboração própria\end{flushleft}
  \label{fig:sparkDataAnalysisDiagram}
\end{figure}

A análise das polaridades dos sentimentos do conteúdo contido nos tweets ocorre durante a última parte do mapeamento, sendo antes disso realizados alguns processamentos para facilitar e viabilizar esse procedimento. Portanto, primeiramente, os textos contidos nos \textit{tweets} são extraídos e formatados para minúsculo. Em seguida, todas as menções são identificadas pelo padrão em que ocorrem no Twitter (@\textit{displayname}, nome exibido para os demais usuários da Rede Social) e removidas, assim como as referências a endereços de sites.

No Twitter, quando um \textit{tweet} é compartilhado ele é marcado com a notação "RT", abreviação de \textit{retweet}, a qual também é removida do texto em processamento. Além disso, alguns símbolos são removidos, tais como: ., ., \!, \%, \#, etc. Sendo esse o conjunto de processamentos realizados para "limpar" inicialmente o texto, após o qual se inicia o Processamento de Linguagem Natural.

Com esse prósito, usou-se a biblioteca OpenNLP \cite{OpenNlp} para a tokenização dos \textit{tweets}. Após a obtenção dos \textit{tokens}, outros processamentos foram necesssários para melhorar o desempenho da fase seguinte, como a substituição das palavras normalmente abreviadas (vc - você, msm - mesmo, pq - porque, q - que, n - não, etc) e de expressões (sqn - só que não, kkk, hahaha, rsrsrs, para situações comumente engraçadas) para seus respectivos formatos formais, utilizando dicionários previamente construídos. Além disso, foram removidos os \textit{tokens} contendo "\textit{stopwords}" (palavras vazias), termo utilizado para as palavras comuns de um certo idioma \cite{DataMining}.

Após a obtenção dos \textit{tokens}, foram atribuídas a eles \textit{tags} referentes as suas respectivas classes gramáticais, e, por fim, associadas a uma \textit{part-of-speech} para cada \textit{tweet}, usando os \textit{tokens} e \textit{tags} obtidas, finalizando a parte do Processamento de Linguagem Natural. Seguindo então, para a última etapa, que é a da análise de polaridade dos sentimentos, tendo como base para isso os adjetivos presentes em cada \textit{tweet}.

A análise das polaridade dos sentimentos foi realizada com o suporte do Sentilex (versão 1), que é um léxico de sentimentos para o Português, constituído de 6.321 lemas adjectivais (por convenção, na forma masculina singular) e 25.406 formas flexionadas, contendo como um de seus atributos a polaridade do adjectivo. As polaridades são classificadas em positivo (67\% de precisão), negativo (82\% de precisão), ou, neutro (45\% de precisão), possibilitando estimar o sentimento expresso por um determinado texto \cite{Sentilex}.

Os sentimentos são estimados contabilizando as polaridades presentes em cada \textit{tweet} e o sentimento expresso pelos \textit{emotions} (se houver), assim sendo, por exemplo, o emotion "(:" incrementa 1 para a polaridade postiva, e 1 para a negativa caso seja ":(". Também, considera-se a presença de advérbios de negação, os quais modificam o significado do verbo, adjetivo e de outros advérbios \cite{Priberam}, alterando consequentemente a polaridade. Por fim, é realizada uma simples normatização com os somatórios das polaridades positivas e negativas, seguindo o seguinte modelo:
{\begin{center} score = ($\Sigma$ positivo - $\Sigma$ negativo) $\div$  ($\Sigma$ positivo + $\Sigma$ negativo)\end{center}}

Caso o \textit{score} seja menor do que zero, o \textit{tweet} é classificado com polaridade negativa, se o seu complemento for maior do que 0.5, tem-se polaridade positiva e se igual a zero, neutra. Sendo assim, as informações sobre a polaridade (sentimento) do \textit{tweet}, seu id e suas respectivas menções (recuperadas do \textit{tweet} original) são armazenadas no banco de dados não relacional MongoDB. As polaridades são exibidas no mapa da aplicação web.

O código dessa aplicação está disponível no repositório localizado em \cite{GitRepository}, sendo "spark-data-analysis" o nome do projeto, e seu respectivo diagrama de classe é ilustrado na Fig. \ref{fig:sparkDataAnalysisClassDiagram}

\begin{figure}[!htb]
  \centering
    \includegraphics[width=0.8\textwidth]{Imagens/sparkDataAnalysisClassDiagram.png}
  \caption{Diagrama de classes da aplicação utilizando o Spark Streaming}
	\begin{flushleft}{\bf Fonte:} Elaboração própria\end{flushleft}
  \label{fig:sparkDataAnalysisClassDiagram}
\end{figure}

\subsection{Aplicação para processamento de stream de tweets, utilizando Storm}
\label{stormApp}

A aplicação que utiliza o Storm para o processamento de \textit{stream} de \textit{tweets}, foi desenvolvida utilizando a linguagem de programação Java. Nela é construída uma topologia, ilustrada na Fig. \ref{fig:stormTopologyApp}, composta por um \textit{Spout} (classe Twitter), responsável pela conexão ao Twitter e coleta dos \textit{tweets}, tendo como filtro o nome das contas das prefeituras no Twitter, utilizando a biblioteca Twitter4J.

\begin{figure}[!htb]
  \centering
    \includegraphics[width=0.8\textwidth]{Imagens/stormTopologyApp.png}
  \caption{Topologia da aplicação utilizando Storm}
	\begin{flushleft}{\bf Fonte:} Elaboração própria\end{flushleft}
  \label{fig:stormTopologyApp}
\end{figure}

Em sequência, há seis \textit{bolts}, responsáveis pelo processamento (o mesmo realizado pela aplicação Spark) dos \textit{tweets} coletados. O primeiro deles, classe TweetCleanerBolt, ilustrada na Fig. \ref{fig:stormApplicationClassDiagram}, remove as menções e \textit{urls} contidas no \textit{tweet}, após isso os simbolos existentes são removidos pelo \textit{bolt} Symbols Cleaner.

Continuando, a parte do Processamento de Linguagem Natural é realizado pelos \textit{bolts} Tokenizer e Tag. Na finalização do processo, o \textit{bolt} SentimentAnalyser calcula a polarização de cada \textit{tweet}, emitindo-os para o \textit{bolt} Persisting, responsável pelo armazená-los no banco de dados não relacional MongoDB. Vale ainda mencionar, que os resultados de cada bolt são setados na classe TweetStream, do modelo da aplicação, o que foi necessário devido ao fato de nem todos os tipos de dados serem serializáveis, como o caso do UserMentionEntity, da biblioteca Twitter4J.

O código dessa aplicação está disponível no repositório localizado em \cite{GitRepository}, sendo "storm-data-analysis" o nome do projeto

\begin{figure}[!htb]
  \centering
    \includegraphics[width=1.2\textwidth, angle=90]{Imagens/stormApplicationClassDiagram.png}
  \caption{Diagrama de classes da aplicação utilizando o Storm}
	\begin{flushleft}{\bf Fonte:} Elaboração própria\end{flushleft}
  \label{fig:stormApplicationClassDiagram}
\end{figure}

\section{Estudo comparativo}
\label{caseStudy}

Nessa seção, é realizada uma análise comparativa entre o Apache Storm e Spark, sendo a subseção \ref{rtp} sobre o requisito de Processamento de grande volume de dados em Tempo Real, a \ref{faultTolerance} a respeito de Tolerância a Falhas, a \ref{garantiesProcessing} sobre Garantias de processamento, a \ref{scalability} em relação a Escalabilidade e, por fim, a \ref{programmingModel} sobre o Modelo de Programação de ambas as ferramentas. 

\subsection{Processamento de grande volume de dados em tempo real}
\label{rtp}

Quanto ao requisito de Processamento de grande volumes de dados em Tempo Real, de acordo com a referência \cite{NrtPresentation}, o Apache Spark pode processar até 670k de registros por segundo e por nó, enquanto que o Storm 155k. Portanto, ambas as ferramentas são capazes de processar grande fluxo de dados.

No entanto, elas se diferenciam no requisito de processamento em tempo real. O Spark tem latência de 0.5­2s \cite{DStream2}, e devido a esse delay de até alguns segundos, é considerado uma ferramenta de \textit{Near­ Real­ Time}. O Storm, por outro lado, tem como latência de 1­100ms \cite{DStream}, \cite{DStream2}, sendo por isso um sistema com processamento em \textit{Real Time}.

Como já mencionado na Fundamentação Teórica, quanto menor o valor de latência, mais rápido se obtém resposta a um dado evento. Além disso, no quesito de processamento em tempo real, também é importante avaliar o valor de throughput, o qual no Spark é maior em comparação ao do Storm \cite{DStream}, favorecendo menor tempo de processamento.

Como base no que foi dito anteriormente, nesse quesito o Spark é mais adequado as aplicações desenvolvidas, pois elas estão inseridas num contexto em que a propriedade de \textit{throughput} tem maior relevância. Isso, devido a quantidade de \textit{tweets} processados, tanto para análise das polaridades de sentimentos, com o módulo Spark Streaming, quanto para o processamento das métricas relacionadas a e-Participação.

\subsection{Tolerância a Falhas}
\label{faultTolerance}

Discretized Streams (D­Streams) é um modelo de programação para processamento de \textit{streams} distribuídas, utilizado pelo Spark Streaming, capaz de fornecer Tolerância a Falhas, através do método \textit{parallel recovery} \cite{DStream3}. Nesse modelo, a tolerância a falhas é implementada através do conceito \textit{lineage}, o que permite as informações serem recuperadas paralelamente \cite{DStream4}.

O mecanismo de recuperação via \textit{lineage} é definido por um grafo acíclico dirigido (DAG), por meio do qual RDDs e D­Streams rastreiam, ao nível das partições RDDs, suas respectivas dependências e operações realizadas sob elas \cite{DStream4}. Sendo assim, os RDDs e D­Streams conseguem "saber" como foram construídos. Podendo, consequentemente, cada nó do \textit{cluster} reconstruí-­lo paralela e eficientemente em caso de falhas. Especificamente, o processo de recuperação é realizado computando novamente uma determinada partição RDD, re­executando as \textit{tasks} que a originaram \cite{DStream4}.

Visando prevenir infinitas re­computações, também são realizados \textit{checkpoints} num determinado espaço de tempo, com replicações assíncronas de RDDs. Tal procedimento, não é necessário para todo o conjunto de dados, pois, como já mencionado, a recuperação executada por nós em paralelo é realizada com demasiada eficiência \cite{DStream4}. 

Todo o processo descrito até aqui é confiável quando a fonte dos dados pode ser lida novamente, no caso do Spark Streaming, é necessário haver alguma fonte externa para replicação dos dados \cite{Spark}. Além disso, se o \textit{Driver} for finalizado, devido ao fato dele manter o contexto da aplicação, todo o conteúdo em memória dos \textit{executors} é perdido \cite{Spark}.  

No Storm, a Tolerância a Falhas é aplicada a cada um de seus componentes. Por exemplo, se o \textit{worker} falha, ele é reinicializado pelo \textit{Supervisor} no próprio nó \cite{LearningStorm}. Caso o nó esteja indisposnível, ou, falhando continuadamente, suas \textit{tasks} são então atribuídas a outro disponível no \textit{cluster}, via Nimbus \cite{StormPython}. 

O Nimbus e os \textit{supervisors}, armazenam seus estados no Zookeeper, podendo ser reinicializados sem perdê-los em caso de falha, se houver falha no Zookeeper, outra instância pode ser "eleita" para o lugar dele\cite{LearningStorm}. Caso algum \textit{supervisor} falhe, seus \textit{workers} são reatribuídos pelo Nimbus a outro \textit{supervisor}, no entanto, ficando impedido de receberem novas tuplas \cite{StormPython}.

Por sua vez, o Nimbus, dentre suas atribuições, é responsável também por reinicializar as \textit{tasks} caso uma delas falhe, e se o mesmo acontecer com ele próprio, as \textit{tasks} em execução não são afetadas, mas novas topologias são impedidas de serem submetidas ao \textit{cluster} \cite{LearningStorm}, assim como reatribuições \cite{StormPython}.

O modelo de recuperação de falhas do Spark pode ser uma boa escolha caso a aplicação permita perda de dados, em prol de eficiência \cite{DStream3}. Caso contrário, é necessário configurar uma fonte externa para replicação dos dados que estão sendo processados. Em contraste, a arquitetura do Storm, busca possibilitar que seus componentes falhem havendo pouco prejuízo para a aplicação, ainda assim a replicação pode adicionar mais uma camada de confiabilidade. 

Levando em consideração o exposto acima, a aplicação desenvolvida para o processamento de métricas, realiza-o em \textit{batch}, podendo ter acesso a fonte de dados para coletá-los novamente, em caso de falha. Além disso, a eficiência foi priorizada, não havendo prejuízo ao utilizar o Spark. Para aplicação que realiza análise de polaridade dos sentimentos, processando \textit{stream} de \textit{tweets}, é mais interessante o suporte a Tolerância a Falhas do Storm, principalmente devido longo tempo de execução dela.

\subsubsection{Garantia de processamento}
\label{garantiesProcessing}

Em adição a subseção anterior, o Spark Streaming e Storm possuem formas diferentes de garantir o processamento de um evento. No Spark Streaming há a garantia de que todo evento será processado exatamente uma vez (\textit{Exactly Once}), sem perdas, ou, duplicadas, via \textit{parallel recovery}, levando em consideração as observações já mencionadas \cite{Spark}.

No Storm, por outro lado, não há suporte ao modelo \textit{Exactly Once}, mas sim aos \textit{At Least Once} e \textit{At Most Once}. Em ordem, a primeira opção permite que o processamento seja realizado no mínimo uma vez, rastreando se o (a) evento (tupla) foi processado(a) ou não, através de seus \textit{IDs} e mensagens informando "\textit{ack}" (tupla processada), podendo haver duplicatas; o oposto ocorre na segunda alternativa, em que perdas são aceitas, processando os eventos no máximo uma vez \cite{Storm}. 

A prosta do Spark Streaming, nesse aspecto, é mais interessante para o processamento de \textit{stream} de \textit{tweets}, por garantir que a informação será processada uma única vez, através do modelo \textit{Exactly Once}.

\subsection{Escalabilidade}
\label{scalability}

Quanto ao requisito de escalabilidade, ambos suportam clusterização, portando são escaláveis horizontalmente, sendo o maior \textit{cluster} Spark conhecido composto por 8.000 nós \cite{Spark}. E, embora não tenha sido encontradas fontes confiáveis divulgando informações sobre o maior \textit{cluster} Storm existente, sabe­-se que ele é capaz de processar um milhão de mensagens com tamanho de 100 byte, por segundo e por nó \cite{Storm}.

\subsection{Modelo de programação}
\label{programmingModel}

Conforme exposto no Cap. \ref{chapter2}, no Spark os RDDs são conjuntos de dados que podem ser manipulados de forma distribuída, sendo possível realizar operações sob eles, gerando novos RDDs, através de transformações, ou, computando-os por meio das ações. O módulo Streaming, utiliza essa unidade como base da abstração DStream, conjunto de RDDs representando um \textit{stream}. Tais conceitos do modelo de programação do Spark podem ser mais difíceis de abstrair, tendo uma classificação de baixo nível, se comparados ao do Storm.

Por outro lado, numa perspectiva alto nível, o Storm propõe o conceito de Topologia, composta por \textit{bolts} e \textit{spouts}. Os \textit{spouts} são responsáveis pela entrada dos \textit{streams} (conjuntos de tuplas) da aplicação, processados posteriormente pelos \textit{bolts}. Devido a essas abstrações, consequentemente, pode haver maior facilidade em programar utilizando o Storm do que o Spark.