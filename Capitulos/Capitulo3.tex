% Capítulo 3
\chapter{Definicação e execução do estudo de caso}
\label{chapter3}

\section{Metodologia de escolha das plataformas para processamento de fluxo de eventos em tempo real}
\label{metodologyOfChoice}

Inicialmente, foi realizada uma pesquisa com a palavra chave "stream processing" e analisados os primeiros artigos (na ordem do resultado e que citavam mais de uma ferramenta) em busca de citações a ferramentas (open source) de processamento de streams em tempo real. Com base nesse resultado, os nomes das plataformas encontradas foram utilizados para buscar a quantidade de referências no Google Scholar (site para publicação de artigos acadêmicos) e Stack Over Flow (site para discussão de assuntos relacionados a desenvolvimento de software). Na Tab. \ref{tab:tableNumberOfMentions}, constam os resultados desse procedimento.

A plataforma Esper mencionada em \cite{InfoQArticle} e \cite{ConfluentArticle}. foi descartada do processo de escolha por ser um componente para CEP, normalmente integrado a ferramentas ESPs, fugindo do escopo desse trabalho \cite{EsperTech}. Sendo assim, continuando a análise, foram também consideradas as características das opções restantes, estudadas superficialmente nos parágrafos seguintes.

\paragraph{Apache Spark Streaming.} Apache Spark Streaming é uma extensão do Spark para processamento de stream, em near real time. Além disso, o Spark possui outros módulos para consultas a banco de dados, grafos, e aprendizado de máquina \cite{Spark}. O processamento de stream é realizado em micro-batching pelo Spark Streaming (um de seus módulos), utilizando uma abstração conhecida como \abrv[DStream -- Discretized Stream]{DStream}, a qual é composta por uma sequências de \abrv[RDD -- Resilient Distributed Dataset]{RDDs (Resilient Distributed Dataset)}, ilustrada na Fig. \ref{fig:dstream}. RDDs abstraem uma coleção de dados distribuídos e manipulados em paralelo. No Spark, também é possível utilizar processamento em batch, independente do módulo que está sendo utilizado \cite{LearningSpark}.

\begin{figure}[!ht]
  \centering
    \includegraphics[width=0.8\textwidth]{Imagens/dstreamImage.png}
  \caption{Ilustração de um DStream}
  {\bf Fonte:} \cite{Spark}
  \label{fig:dstream}
\end{figure}

\paragraph{Apache Flink.} Apache Flink é um plataforma muito semelhante ao Spark. Com suporte a processamento de streams, os quais são definidos por uma abstração conhecida como DataStream, ilustrada na Fig. \ref{fig:flinkProcessingImage}. O processamento em batch é realizado em cima de DataSets, semalhantes as RDDs do Spak. Da mesma forma como o DStream é definido como uma série de RDDS, o DataStream é composto por uma sequência de DataSets. A abstração Sink é utilizada para armazenar e retornar DataSets. Há suporte também para CEP, processamento em grafos, aprendizado de máquina e consulta a banco de dados \cite{Flink}.

\begin{figure}[htb]
  \centering
    \includegraphics[width=0.8\textwidth]{Imagens/flinkProcessingImage.png}
  \caption{Ilustração de um fluxo de processamento no Flink}
  {\bf Fonte:} \cite{FlinkOverView}
  \label{fig:flinkProcessingImage}
\end{figure}

\paragraph{Apache Storm.} Apache Storm é um plataforma para processamento de stream em tempo real. Ao contrário do Spark, tem "one at time" como modelo de processamento de dados. As streams são compostas por tuplas (unidade básica de dados, as quais processadas numa abstração conhecida como Topologia, ilustrada na Fig. \ref{fig:stormTopology}, composta por um \abrv[DAG -- Directed Acyclic Graph]{DAG (Directed Acyclic Graph \cite{GraphTeory})} de spouts e bolts, respectivamente, resposáveis por emitir streams de dados e processá-los \cite{LearningStorm}. 

\paragraph{Apache Samza.} Apache Samza é outra plataforma para processamento de stream em tempo real, utilizando como abstração base o conceito de mensagem (identificadas por offsets, ids), em vez de tupla, ou, DStream. Os streams são separados em partições contendo mensagens ordenadas (acessadas apenas no modo de leitura), sendo processados por jobs responsáveis por ler e emir fluxos. Assim como o Spark, há suporte para processamento em batch, o qual é realizado processando sequências de streams.

\begin{figure}[htb]
  \centering
    \includegraphics[width=0.6\textwidth]{Imagens/samzaPartitionsImage.png}
  \caption{Ilustração de um stream particionado no Samza}
  {\bf Fonte:} \cite{Samza}
  \label{fig:samzaPartitions}
\end{figure}

Após essas breves descrições das plataformas para processamento de eventos em tempo real e da análise realizada do número de citações, o Spark Streaming e Storm foram escolhidas como ferramentas para o trabalho desenvolvido no Cap. \ref{chapter3}. Isso, porque ambas possuem maior número de citações nas fontes pesquisadas, e consequentemente, comunidades maiores, o que pode favorecer melhor documentação, suporte e continuidade desses projetos. 

Sendo assim, como Flink e Samza são semelhantes ao Spark o único critério de diferenciação, superfecialmente, é o tamanho da comunidade e a popularidade que o Spark tem. No demais, o Storm se diferencia com o conceito de topologia, interessante de ser estudado. Devido a isso, o Spark e Storm foram aprofundados no Cap. \ref{chapter2} e utilizados no trabalho a ser apresentado nesse capítulo.

\begin{table}[!htb]	
	\center
		% Título de tabelas sempre aparecem antes da tabela
	\caption{Quantidade de citações a plataformas ESPs por referência}
	\label{tab:tableNumberOfMentions}
	{
		\begin{tabular}{c|c|c|c|c}
			\hline
            {\bf Referência} & {\bf Spark Streaming} & {\bf Storm} & {\bf Flink} & {\bf Samza}\\
			\hline
			\cite{InfoQArticle} & 1 & 1 & 1 & 1\\
			\cite{ConfluentArticle} & 1 & 0 & 0 & 1\\
			\cite{DzoneArticle} & 1 & 1 & 0 & 1\\
			\cite{Datatorrent} & 1 & 1 & 0 & 0\\
			\cite{CakeSolutionsArticle} & 1 & 1 & 0 & 0\\			
			\cite{VenturebeatArticle} & 1 & 1 & 0 & 0\\
			\cite{BravenewgeekArticle} & 1 & 0 & 0 & 1\\
			\cite{GoogleScholar} & 806 & 766 & 171 & 283\\
			\cite{StackOverFlow} & 1541 & 538 & 567 & 87\\
			\hline
			{\bf Total de citações} & 2354 & 1311 & 739 & 374\\
			\hline
		\end{tabular}
	}
	\center{\bf Fonte:} Elaboração própria
\end{table}

\section{Aplicações desenvolvidas para estudo de caso}

Após a escolha das plataformas para processamento de eventos em tempo real, quatro aplicações foram desenvolvidas. A explicada na subseção \ref{batchApp}, visa processar tweets para coletar métricas relacionadas a e-Participação; a da subseção \ref{sparkApp}, processa streams de tweets com o Spark Streaming e realiza processamento de linguagem natural para detectar o sentimento expresso neles; a referente a subseção \ref{stormApp}, realiza o mesmo procedimento, mas com o Storm; por fim, a da subseção \ref{webApp}, exibe numa aplicação web um mapa contendo as informações coletadas nas anteriores.

\sloppy
\subsection{Aplicação para processamento de tweets e coleta de métricas relacionadas a e-Participação}
\label{batchApp}

O primeiro passo no desenvolvimento dessa aplicação, foi decidir as contas das quais os tweets seriam processados. Como, normalmente, as capitais dos estados tem maior concentração de pessoas, optou-se por fazer um levantamento dos perfis oficiais de suas respectivas prefeituras, para então posteriormente realizar o processamento dos tweets. Sendo assim, a Tab. \ref{tab:tweetAccounts} lista as contas relacionadas as prefeituras municipais das capitais dos vinte e sete estados brasileiros.

Em seguida, foram escolhidas quais métricas dessas contas seriam possíveis e importantes de coletar, tendo como referência \cite{AVisionOfSocialMedia}. Sendo assim, selecionou-se as seguintes, respectivas ao Twitter: média do número de tweets, seguidores, retweets (compartilhamento de um determinado tweet), comentários realizados por usuários, réplicas a tweets e tempo de resposta. As métricas referentes ao número de usuários acompanhando as listas (junções de timelines) do perfil e o total delas existentes foram desconsideras, pois são relacionadas a contas diferentes das em questão.

De acorco com \cite{AVisionOfSocialMedia}, através dessas métricas é possível obter indicadores relacionados ao nível e-Participação. Alguns dos indicadores propostos  pela \abrv[SNR -- Social Network Ratio]{SNR (Social Network Ratio)} para Redes Sociais são: Atividade, ou, audiência estimada; Tamanho, ou, esforço realizado pelo perfil para se comunicar; Visibilidade, ou, número total de menções ao perfil; Interação, ou, capacidade de impacto (viralização) da comunicação \cite{AVisionOfSocialMedia}.

Portando, pode-se mapear a métrica média de seguidores ao indicador Atividade, e a de menções para o de Visibilidade; da mesma forma, as médias sobre tweets, réplicas por dia e tempo de resposta ao indicador Tamanho; por último, as médias de retweets e favoritos ao de Interação. A Fig. \ref{fig:twitterDataAnalysisClassDiagram} exibe o diagrama de classes da aplicação desenvolvida para o processamento de tweets e coleta dessas métricas.

\begin{figure}[!htb]
  \centering
    \includegraphics[width=1.2\textwidth, angle=90]{Imagens/twitterDataAnalysisClassDiagram.png}
  \caption{Diagrama de classes da aplicação desenvolvida para processamento e coleta de métricas relacionadas a e-Participação}
	\begin{flushleft}{\bf Fonte:} Elaboração própria\end{flushleft}
  \label{fig:twitterDataAnalysisClassDiagram}
\end{figure}

A aplicação exibida no diagrama de classes da Fig. \ref{fig:twitterDataAnalysisClassDiagram} foi desenvolvida na linguagem de programação Java, devido a sua praticidade de uso, utilizando o framework para Web services, Apache CXF \cite{ApacheCXF}, para expor dois de seus serviços através de uma REST API. O primeiro deles é exposto pela interface ITweetService, e o segundo pela ISparkService, pelos seguintes endpoints, respectivamente: "$\backslash$tweets" e "$\backslash$metrics", permitindo intregrá-la a aplicação web descrita na subseção \ref{webApp}. 

A classe que implementa a interface ITweetService, é responsável por realizar a coleta dos 3.200 tweets mais recentes (se disponíveis) de cada conta, através do endpoint "statuses/user\_timeline". Tal quantidade é limitada pela API do Twitter, a qual pode ser alcançada por no máximo 180 requisições, num intervalo de 15 minutos, com autenticação via conta de usuário \cite{TwitterDevelopers}.

Outro endpoint utilizado foi "search/tweets", para pesquisar as menções realizadas pelos cidadãos as contas das prefeituras. O limite de coleta é de 100 tweets coletados para cada requisição, sendo possível realizar 180 a cada 15 minutos. Os endpoints da API do Twitter foram acessados com o suporte da biblioteca Twitter4J \cite{Twitter4J}.

Durante a coleta dos tweets, eles são mapeados para as seguintes classes do modelo da aplicação: UserInfo, que contém as informações respectivas ao usuário da conta (número de seguidores, tweets, localização, username e data de criação da conta), e TweetInfo, contendo as relacionadas ao tweet (data de criação, id do tweet de réplica e a qual usuário ele se refere, quantidade de retweets, favoritos, se é menção ou não, e o tempo de resposta calculado). Em seguida, os modelos são persistidos via a interface ITweetsDAO, a qual se comunica com o banco de dados não relacional MongoDB \cite{Mongo}.

Os tweets coletados por essa aplicação são os mais recentes e anteriores a data 18/06/2016 (incluindo-a). Como essa coleta não foi realizada sob um stream de tweets, a interface ISparkService expõe o serviço responsável por realizar o processamento em batch desses tweets, coletando as métricas relacionadas a e-Participação. Sendo assim, cada métrica é recuperada do banco de dados e mepeadas para um RDD de doubles, quando números, ou, de strings, no caso da data.

\begin{figure}[!htb]
  \centering
    \includegraphics[width=0.6\textwidth]{Imagens/sparkDiagramMapToDouble.png}
  \caption{Diagrama do mapeamento entre um Resilient Distributed Dataset de Long para Double}
	\begin{flushleft}{\bf Fonte:} Elaboração própria\end{flushleft}
  \label{fig:sparkDiagramMapToDoble}
\end{figure}

Sendo assim, após recuperar as métricas, é possível mapeá-las para um RDD de doubles, por meio do qual são obtidos os valores relacionados as suas respectivas médias, medianas, variâncias, máximos, mínimos e desvios padrões. As informações sobre datas, como strings, são mapeadas para o valor 1, representando a ocorrência de um tweet nesse dia; compondo uma sequência de pares, que permite obter e mapear as quantidades de tweets por dia a um RDD de doubles. Tais processos de mapeamentos são ilustrados nas Fig. \ref{fig:sparkDiagramMapToDoble} e Fig.  \ref{fig:sparkDiagramMapDateToDouble}.

Por fim, a interface IFusionTable é utilizada para submeter os valores das métricas relacionadas e-Participação a uma Fusion Table \cite{eParticipationMetrics}, via a API do Google Fusion Tables (aplicação web experimental para visualização de dados, coleta e compartilhamento de tabelas \cite{FusionTables}). Os valores dessa tabela são utilizados para criar o mapa contido na aplicação web.

\begin{figure}[!htb]
  \centering
    \includegraphics[width=0.7\textwidth]{Imagens/sparkDiagramMapDateToDouble.png}
  \caption {Diagrama do mapeamento entre um Resilient Distributed Dataset de Datas para suas respectivas frequências em Double}
	\begin{flushleft}{\bf Fonte:} Elaboração própria\end{flushleft}
  \label{fig:sparkDiagramMapDateToDouble}
\end{figure}

O código dessa aplicação está disponível no repositório localizado em \cite{GitRepository}, sendo "twitter-data-analysis" o nome do projeto.

\begin{table}[!htb]	
	\center
		% Título de tabelas sempre aparecem antes da tabela
	\caption{Contas do Twitter relacionadas as prefeituras municipais das capitais dos vinte e sete estados brasileiros}
	\bigskip
	\label{tab:tweetAccounts}
	{
		\begin{tabular}{c|c|c}
			\hline
            {\bf Estado} & {\bf Capital} & {\bf Conta no Twitter}\\
			\hline
			Acre & Rio Branco & PrefRioBranco\\
			Alagoas & Maceió & PrefMaceio\\
			Amapá & Macapá & PMMacapa\\
			Amazonas & Manaus & PrefManaus\\
			Bahia & Salvador & agecomsalvador\\			
			Brasília & Brasília & Gov\_DF\\
			Ceará & Fortaleza & prefeiturapmf\\
			Espírito Santo & Vitória & VitoriaOnLine\\
			Goiás & Goiánia & PrefeituraGy\\
			Maranhão & São Luís & PrefeituraSL\\
			Mato Grosso & Cuiabá & prefeitura\_CBA\\
			Mato Grosso do Sul & Campo Grande & cgnoticias\\
			Minas Gerais & Belo Horizonte & prefeiturabh\\
			Paraná & Curitiba & Curitiba\_PMC\\
			Paraíba & João Pessoa & pmjponline\\
			Pará & Belém & prefeiturabelem\\
			Pernambuco & Recife & prefrecife\\
			Piauí & Teresina & prefeitura\_the\\
			Rio Grande do Norte & Natal & NatalPrefeitura\\
			Rio Grande do Sul & Porto Alegre & Prefeitura\_POA\\
			Rio de Janeiro & Rio de Janeiro & Prefeitura\_Rio\\
			Rondônia & Porto Velho & prefeitura\_pvh\\
			Roraima & Boa Vista & PrefeituraBV\\
			Santa Catarina & Florianópolis & scflorianopolis\\
			Sergipe & Aracaju & PrefeituraAracaju\\
			São Paulo & São Paulo & prefsp\\
			Tocantins & Palmas & cidadepalmasy\\
			\hline
		\end{tabular}
	}
		\begin{flushleft}{\bf Fonte:} Elaboração própria\end{flushleft}
\end{table}

\bigskip
\bigskip
\bigskip
\bigskip

\subsection{Aplicação para processamento de stream de tweets, utilizando Spark Streaming}
\label{sparkApp}

A aplicação que utiliza o Spark Streaming, foi desenvolvida na linguagem de programação Java. No início de sua execução, é criado um contexto de stream no qual é definindo o cluster onde ela será executada e o intervalo de criação de cada RDD. Tais Resilient Distributed Datasets, são compostos ordenadamente em sequência, formando a abstração conhecida como DStream. No nosso caso, cada RDD é criado após  30000ms (mile segundos).

O processo mencionado anteriormente, começa após a inicialização do contexto de stream, sendo os tweets coletados pela classe TwitterUtils (do próprio Spark Streaming). Durante a coleta dos streams de tweets (eventos), cada RDD é mapeado para a classe TweetInfo (do modelo da aplicação), através de uma transformação map. Na sequência, as ações forEachRDD e collect são executadas para inserir os tweets processados no banco de dados não relacional MongoDB, conforme ilustrado na Fig. \ref{fig:sparkDataAnalysisDiagram}.

\begin{figure}[!htb]
  \centering
    \includegraphics[width=0.8\textwidth]{Imagens/sparkDataAnalysisDiagram.png}
  \caption{Fluxo do processamento de dados da aplicação utilizando o Spark Streaming}
	\begin{flushleft}{\bf Fonte:} Elaboração própria\end{flushleft}
  \label{fig:sparkDataAnalysisDiagram}
\end{figure}

A análise de sentimentos do conteúdo contido nos tweets ocorre durante a última parte do mapeamento, sendo antes disso realizados alguns processamentos para facilitar e viabilizar esse procedimento. Portanto, primeiramente, os textos contidos nos tweets são extraídos e formatados para minúsculo. Em seguida, todas as menções são identificadas pelo padrão em que ocorrem no Twitter (@displayname, nome exibido para os demais usuários da Rede Social) e removidas, assim como as referências a endereços de sites.

No Twitter, quando um tweet é compartilhado ele é marcado com a notação "RT", abreviação de retweet, a qual também é removida do texto em processamento. Além disso, alguns símbolos são removidos, tais como: ., ., \!, \%, \#, etc. Sendo esse o conjunto de processamentos realizados para "limpar" inicialmente o texto, após o qual se inicia o processamento de linguagem natural.

Com esse prósito, usou-se a biblioteca OpenNLP \cite{OpenNlp} para a tokenização dos tweets. Após a obtenção dos tokens, outros processamentos foram necesssários para melhorar o desempenho da fase seguinte, como a substituição das palavras normalmente abreviadas (vc - você, msm - mesmo, pq - porque, q - que, n - não, etc) e de expressões (sqn - só que não, kkk, hahaha, rsrsrs para situaões comumente engraçadas) por seus formatos formais, utilizando dicionários previamente construídos. Além disso, foram removidos os tokens contendo "stopwords" (palavras vazias), termo utilizado para as palavras comuns de um certo idioma \cite{DataMining}.

Após a obtenção dos tokens, foram atribuídas a eles tags referentes as suas respectivas classes gramáticais, e, por fim, associadas uma part-of speech para cada tweet, usando os tokens e tags obtidos, finalizando a parte do processamento de linguagem natural. Indo então para a última etapa, que é a da análise de sentimentos, tendo como base para isso os adjetivos presentes em cada tweet.

A análise de sentimentos foi realizada com o suporte do Sentilex (versão 1), que é um léxico de sentimentos para o Português, constituído de 6.321 lemas adjectivais (por convenção, na forma masculina singular) e 25.406 formas flexionadas, contendo como um de seus atributos a polaridade do adjectivo. As polaridade são classificadas em positivo (67\% de precisão), negativo (82\% de precisão), ou, neutro (45\% de precisão), possibilitando estimar o sentimento expresso por um determinado texto \cite{Sentilex}.

Os sentimentos são estimados contabilizando as polaridades presentes em cada tweet e o sentimento expresso pelos emotions (se houver), assim sendo, por exemplo, o emotion "(:" incrementa 1 para a polaridade postiva, e 1 para a negativa caso seja ":(". Também, considera-se a presença de advérbios de negação, os quais modificam o significado do verbo, adjetivo e de outros advérbios \cite{Priberam}, alterando consequentemente a polaridade. Por fim, é realizada uma simples normatização com os somatórios das polaridades positivas e negativas, seguindo o seguinte modelo:
{\begin{center} score = ($\Sigma$ positivo - $\Sigma$ negativo) $\div$  ($\Sigma$ positivo + $\Sigma$ negativo)\end{center}}

Caso o score seja menor do que zero, o tweet é classificado com polaridade negativa, se o seu complemento for maior do que 0.5, tem-se polaridade positiva e se igual a zero, neutra. Sendo assim, as informações sobre a polaridade (sentimento) do tweet, seu id e suas respectivas menções (recuperadas do tweet original) são armazenadas no banco de dados não relacional MongoDB. As polaridades são exibidas no mapa da aplicação web.

O código dessa aplicação está disponível no repositório localizado em \cite{GitRepository}, sendo "spark-data-analysis" o nome do projeto, e seu respectivo diagrama de classe é ilustrado na Fig. \ref{fig:sparkDataAnalysisClassDiagram}

\begin{figure}[!htb]
  \centering
    \includegraphics[width=0.8\textwidth]{Imagens/sparkDataAnalysisClassDiagram.png}
  \caption{Diagrama de classes da aplicação utilizando o Spark Streaming}
	\begin{flushleft}{\bf Fonte:} Elaboração própria\end{flushleft}
  \label{fig:sparkDataAnalysisClassDiagram}
\end{figure}

\subsection{Aplicação para processamento de stream de tweets, utilizando Storm}
\label{stormApp}
 
\subsection{Aplicação Web}
\label{webApp}

