% Fundamentação Teórica
\chapter{Fundamentação Teórica}
\label{chapter2}

Nesse capítulo, são apresentados os conceitos relacionados a essa monografia, os quais estão divididos nas seguintes seções: \ref{smartCities}, sobre a temática de Cidades Inteligentes; \ref{realTimePlatforms}, a respeito de Plataformas de processamento em tempo real; \ref{sparkSection} e \ref{stormSection}, sobre o Apache Spark e Storm, respectivamente. 

\section{Cidades Inteligentes}
\label{smartCities}

Projeções da Organização das Nações Unidas \abrv[ONU --­ Organização das Nações Unidas]{(ONU)}, indicam que a população mundial urbana atual passará de 3.9 bilhões de pessoas para 6.3 bilhões em 2050, representando 66\% do total de habitantes, 9.54 bilhões \cite{OnuArticle}. Tal crescimento populacional, pertencente a classe de problemas de solução não técnica, de acordo com o fenômeno conhecido por Tragédia dos Comuns, no qual uma alta demanda de recursos finitos (água, energia, alimentos, estradas, etc.) os tornam escassos \cite{TragedyOfTheCommons}, podendo resultar em consequências graves como a miséria.

A ONU, por sua vez, indicam algumas estratégias políticas para lidar com esse problema, tais como: incentivo a migração interna; redistribuição espacial da população; expansão da infra-estrutura; garantia de acesso a serviços e oportunidades de trabalho; uso de Tecnologias da Informação e Comunicação \abrv[TICs --­ Tecnologias da Informação e Comunicação]{(TICs)}, para melhoraria na entrega de serviços \cite{OnuArticle}, etc. Podendo nesse último ponto, por exemplo, haver exploração das TICs visando a implantação de iniciativas relacionadas a Cidades Inteligentes. 

As Cidades Inteligentes, são locais nos quais, principalmente, busca-se transformar os sistemas da cidade e otimizar o uso de seus recursos finitos, melhorando assim a eficiência da economia, possibilitando desenvolvimento político, social, cultural e urbano \cite{AVisionOfSocialMedia}. Apesar dessas possíveis transformações e otimizações, é importante salientar, novamente, que nenhuma abordagem técnica resolve por si só as problemáticas decorrentes do crescimento populacional \cite{TragedyOfTheCommons}.

Uma das problemáticas amenizadas pelas Cidades Inteligentes, é a da demanda por eficiência energética (decorrente das mudanças climáticas), a qual requer das cidades menos emissão de gás carbono, o que pode ser obtido, por exemplo, utilizando iluminações públicas mais eficientes, com investimentos em prédios sustentáveis (energeticamente sustentável e com uso de áreas verdes), transportes públicos e ciclovias. Outra possibilidade, é a de desenvolvimento de serviços digitais capazes de ajudar os cidadãos com questões cotidianas, como a chamar um táxi, saber a localização de um ônibus, encontrar a rota com menos congestionamento de carros, reportar crimes, comunicar-se com o governo, etc \cite{CiscoArticle}.

O problema relacionado a Cidades Inteligentes tratado por essa monografia, como já mencionado, insere-se no contexto de processamento de grande volume de dados, decorrente, principalmente, ao aumento de objetos conectados à Internet (relacionados ao conceito de IoT - \textit{Internet of Things}, explicado em \ref{iotSection}), com previsão de existirem 212 bilhões até 2020. E, também, ao crescimento do número de pessoas conectas (o que com o crescimento populacional tende a aumentar), prevendo-se 3.5 bilhões em 2017, sendo 64\% via dispositivos móveis \cite{CiscoArticle}.

Ainda, mais especificamente, espera-se que a quantidade de dados existentes dobre a cada dois anos até 2020 \cite{EmcArticle2}. Além desses fatores, outros têm contribúido para essa expanção, tais como: o crescimento do uso da Internet, \textit{smartphones} e Redes Sociais; a queda do custo de equipamento para criar, capturar, administrar, proteger e armazenar informação; migração da TV analógica para a digital; crescimento dos dados gerados por máquinas, incluindo imagens de câmeras de segurança e da informação sobre informação \cite{CiscoArticle}.

\subsection{Internet das Coisas}
\label{iotSection}

Considerando o exposto pela seção \ref{smartCities}, a expansão do número de pessoas e coisas conectadas à Internet, chegar­-se-­á um patamar em que tudo o que é possível estar, estará conectado, ampliando o conceito de Internet das Coisas para o de Internet de Todas as Coisas, segundo a Cisco \cite{CiscoIoE}. Em tal cenário, cerca de 44 trilhões de \textit{gigabytes} serão gerados \cite{EmcArticle2}, os quais processados por sistemas inteligentes, ajudarão no surgimento de serviços de grande impacto no cotidiano de uma cidade \cite{CiscoArticle}.

Principalmente, aqueles que monitoram e reportam continuadamente qualquer modificação que ocorra em um determinado cenário. Por exemplo, no contexto de saúde pública, é possível monitorar as condições do organismo de um paciente, notificando os médicos responsáveis caso a pessoa esteja em risco, através de uma rápida comunicação e resposta a tal acontecimento. Alguns dos sistemas semelhantes a esse são exemplificados na Fig. \ref{fig:iotImage}.

\begin{figure}[htb]
  \centering
    \includegraphics[width=1\textwidth]{Imagens/iotImage.png}
  \caption{Cidade num invólucro digital}
  {\bf Fonte:} \cite{CiscoArticle}
  \label{fig:iotImage}
\end{figure}

Na Fig. \ref{fig:iotImage}, organizações, pessoas e objetos estão conectados, criando um invólucro digital, composto por representações de serviços conectados a nuvem, tais como: o de um (i) Hospital Inteligente, conectado a dispositivos médicos inteligentes e a ambulâncias; (ii) Centro Digital de Controle e Comando Municipal, integrado a um sistema inteligente de segurança pública e armazenamento de dados; (iii) Sistema de Otimização de Fluxo de Tráfico, conectado a um sistema de estradas inteligentes agregadas a câmeras de controle de tráfico; (iv) Fábrica Inteligente, integrada a um sistema de otimização de logística e fábrica; (v) Administração de Energia Doméstica e (vi) \textit{Smart Grid} (um novo modelo de Redes Elétricas \cite{IeeeArticle}) e (vii) Otimização de Rede de Comunicação.

Tais serviços não serão estudados nesse trabalho, foram apenas referenciados visando demonstrar uma pequena parte da gama de possibilidades existentes em Cidades Inteligentes, Internet das Coisas, e a problemática relacionada ao processamento de dados.

\subsection{Requisitos de uma aplicação de Cidade Inteligente}

Devido a grande quantidade de dados existentes, conforme mencionado na seção \ref{iotSection}, a capacidade de processar grandes volumes de dados pode ser um dos requisitos necessários a uma aplicação de Cidade Inteligente. Nesse contexto, por exemplo, pode ser importante observar duas métricas: o valor de (i) throughput e  o de (ii) latência, sendo o primeiro termo referente a taxa de processamento e, o segundo, a variação do tempo entre um estímulo e resposta \cite{WebPerformanceTuning}.

Dependendo dos requisitos da aplicação, a latência talvez seja mais interessante de ser priorizada quando respostas a determinados eventos precisam ser no menor intervalo de tempo possível (menos de um segundo). Por outro lado, o valor de throughput, pode ser mais adequado se a aplicação necessitar processar grandes volumes de dados dentro de um valor de latência aceitável (no máximo alguns segundos) \cite{Survey}.

Outro requisito importante de ser analisado, é o de tolerância a falhas (necessário quando a aplicação está inserida em ambientes distribuídos, ou, de incertezas), o qual permite o funcionamento do sistema mesmo que uma falha (conceito explicado na seção \ref{realTimePlatforms}) ocorra, o que pode ser obtido, por exemplo, por meio de replicação \cite{SistemasDistribuidos}. Além disso, pode existir a necessidade de antender o requisito de escalabilidade, através do qual é possível oferecer um serviço de alta qualidade conforme o aumento da demanda, adicionando novos recursos (escalabilidade horizontal), ou, melhorando os existentes (escalabilidade vertical) \cite{Sommerville}.

Por fim, algumas aplicações precisam do requisito de Processamento em Tempo Real, quem tem como uma de suas principais características um limite de tempo pré-determinado para as respostas aos eventos do sistema \cite{Sommerville}. Após mencionar esses requisitos, é importante observar o Modelo de Programação (ou, as abstrações) da plataforma que será utilizada no processo de desenvolvimento de uma aplicação, pois, ele (elas) pode impactá-los.

\subsection{e-Participação}

Uma das temáticas abordadas em Cidades Inteligentes, é a de promover novos meios para a participação do cidadão nas questões relaciondas a gestão da cidade \cite{AVisionOfSocialMedia}. As Redes Sociais são um dos principais meios onde essa interação pode ocorrer, posto que elas compostas por um conjunto de pessoas (ou, organizações), representando nós de uma rede, conectadas através de um conceito abstrato de relacionamento \cite{DccArticle}. 

Sendo assim, tal ambiente virtual, tem proporcionado um novo espaço para que os cidadãos possam participar de processos de consulta e deliberação (exame e dicussão de um assunto \cite{Priberam}), atuando com os governos como atores de processos de tomadas de decisão \cite{DccArticle}. Essa participação quando ocorre em ambientes virtuais, como Redes Sociais, aplicativos, wiki, fórum, blogs, dentre outros \cite{AnpocsArticle}, defini-se pelo conceito de e-Participação, dentro de outro mais abrangente que é o de Governo Eletrônico. 

O Governo Eletrônico é caracterizado pelo uso de TICs pelo governo público, buscando prover melhores serviços, informações e conhecimento ao cidadão; facitando o acesso ao processo político e incentivando a participação \cite{AnpocsArticle}. Ele pode ser dividido, principalmente, nos três campos seguintes: e-Administração, a respeito do funcionamento interno do poder público; e-Governo, no tocante a entrega e fornecimento de serviços e informações qualificadas aos cidadãos; e-Democracia, relacionada a ampliação da participação da sociedade na tomada de decisão, sendo a e-Participação uma sub-área desse último \cite{AnpocsArticle}.

A intenção da e-Participação é reforçar e renovar as interações entre o setor público, os políticos e cidadãos; tanto quanto possível no processo democrático \cite{AnpocsArticle}. Além disso, a e-Participação não pode ser avaliada somente por seus aspectos técnicos, mas também quanto a capacidade de incrementar a democracia \cite{AnpocsArticle}.

Um dos desafios nessa área é avaliar as ferramentas apoiadas pelas TICs, quanto as formas de engajamento existentes, como informação, consulta, ou, participação ativa \cite{AnpocsArticle}. Ainda, segundo citação contida em \cite{AnpocsArticle}, a e-Participação é um conjunto de várias tecnologias, medidas sociais e políticas, havendo a necessidade de melhorar a compreensão das relações entre esses componentes e como suas respectivas práticas de avaliação podem ser aplicadas a e-Participção como um todo.

Com isso, para que os processos que a envolvem sejam eficazes é importante considerar os ambientes online e off-line, ou seja, incrementando os métodos tradicionais (conferências, fóruns, conselhos, ouvidorias, audiências, consultas, reuniões, comitês, grupos de trabalho e mesas de negociação) com as possibilidades da e-Particição, estendendo-a ainda aos grupos desfavorecidos e desconectados \cite{AnpocsArticle}. Dito isso, no parágrafo seguinte, são referenciados alguns dos diferentes níveis de e-Participação.   

\paragraph{Níveis de e-Participação.} No nível e-Informação, há um canal unidirecional, visando apenas fornecer informações de interesse cívico; no de e-Consulta, a comunicação é biderecional, via coleta de opiniões e alternativas; no de e-Envolvimento busca-se garantir a compreensão e levar em consideração os anseios do cidadão; em e-Colaboração, a comunicação é bidirecional, e o cidadão participa ativamente no desenvolvimento de alternativas e indentificação de melhores soluções; por fim, no de e-Empoderamento, a influência, controle e elaboração de políticas pelo e para o público é viabilizada \cite{AnpocsArticle}. 

\section{Plataformas de processamento em tempo real}
\label{realTimePlatforms}

As plataformas de processamento em tempo real \abrv[RTC --­ Real­ Time Computing]{(RTC, \textit{Real­ Time Computing})}, compostas por hardware ou software, são sistemas que tem como um dos principais requisitos emitir respostas a eventos de acordo com um determinado \textit{deadline} (limite de tempo). Sendo assim, a corretude da computação não depende apenas da corretude lógica, mas também dos resultados serem produzidos de acordo com o \textit{deadline} especificado \cite{RtcAsNewDiscipline}, \cite{Sommerville}.

Normalmente, os resultados são obtidos através de processamentos realizados por um conjunto de \textit{tasks} (tarefas) cooperativas, iniciadas por eventos do sistema. Os eventos são dependentes do ambiente no qual estão inseridos, podendo ocorrer periodicamente (de forma regular e previsível), ou, aperiodicamente (irregulares e imprevisíveis) \cite{RtcAsNewDiscipline}, \cite{Sommerville}.

As \textit{tasks} podem ter uma relação de interdependência e ao mesmo tempo nem todos os eventos que as originaram necessitarem de ser processados dentro de um \textit{deadline}. Apesar disso, nenhuma \textit{task} pode vir a comprometer o processamento de outra \cite{RtcAsNewDiscipline}.  

Com isso, os \textit{deadlines} podem ser classificados em \textit{hard}, \textit{firm}, ou, \textit{soft}. No primeiro caso, respectivamente, as respostas a todos os eventos devem necessariamente ocorrer dentro do  \textit{deadline}  definido; no segundo, \textit{deadlines} esporadicamente não atendidos são aceitos; no terceiro, \textit{deadlines} não alcançados são permitidos frequentemente \cite{RtcAsNewDiscipline}. Além desses categorias, há os sistemas com \textit{delay} (atraso) introduzido entre o intervalo de tempo de estímulo e resposta, os quais são classificados como \abrv[NRT -- Near Real Time]{\textit{Near Real Time} (NRT)}, ou seja, são sistemas de processamento em "quase tempo real".

Sendo assim, na categoria \textit{hard}, é considerado como falha se o tempo estimado para um processamento não for atendido, e nas demais, a ocorrência disso resulta numa degradação (contínua de acordo com a quantidade de \textit{deadlines} não atendidos) \cite{RtcAsNewDiscipline}, \cite{Sommerville}. Entende-se por falha quando o usuário não recebe algo esperado (por exemplo, \textit{deadline} não atendido) devido a um erro de sistema. Sendo esse erro um estado errôneo resultante de um defeito (característica do sistema que pode resultar em erro). E, degradação, como decréscimo da qualidade (conceito subjetivo, de acordo com os requisitos da aplicação) do sistema \cite{Sommerville}.

Por fim, é importante mencionar também que uma falha de sistema pode comprometer o requisito de Confiança e prejudicar um grande número de pessoas \cite{RtcAsNewDiscipline}, \cite{Sommerville}. Na Fig. \ref{fig:reliabilityDiagram} a seguir, são ilustradas as principais propriedades desse requisito:

\begin{figure}[htb]
  \centering
    \includegraphics[width=1\textwidth]{Imagens/reliabilityDiagram.png}
  \caption{Principais propriedades de Confiança}
  {\bf Fonte:} \cite{Sommerville}
  \label{fig:reliabilityDiagram}
\end{figure}

\subsection{Processamento de fluxo de eventos em tempo real}
\label{espSubsection}

Fluxo (ou \textit{stream}) de eventos, basicamente, pode ser entendido como uma série de eventos em função do tempo \cite{Datatorrent}, \cite{Complexevents}. Dentro desse escopo, duas abordagens de processamento são importantes diferenciar: \abrv[ESP -- Event Stream Processing]{(i) ESP (\textit{Event Stream Processing}, ou, Processamento de Fluxo de Eventos)} e \abrv[CEP -- Complex Event Processing]{(ii) CEP (\textit{Complex Event Processing}, ou, Processamento Complexo de Eventos)}. A primeira, costuma-se focar principalmente com questões de baixo nível, relacionadas a como processar eventos em tempo real atendendo requisitos de escalabilidade, tolerância a falha, confiabilidade, etc \cite{ConfluentArticle}.

Na segunda abordagem, os \textit{streams} são utilizados para criar uma nuvem de eventos, parcialmente ordenados por tempo e causalidade, conceito conhecido como \abrv[POSET -- Partially ordered set of events]{POSET (\textit{Partially Ordered Set of Events})} \cite{Complexevents}. Sendo assim, normalmente, visa-se trabalhar questões de alto nível, utilizando \textit{posets} para a criação de padrões de eventos, envolvendo seus relacionamentos, estrutura interna, etc. Com esse conjunto de informações é possível compor eventos complexos, os quais podem ser consultados continuadamente \cite{ConfluentArticle}. 

Portanto, nessa monografia, será utilizada a primeira abordagem (ESP) para processamento de eventos, por ser mais adequada ao objetivo proposto no Cap. \ref{objective}. Em ESPs, algumas plataformas processam os \textit{streams} continuadamente conforme são recebidos pelo sistema; paradigma conhecido como \textit{One at Time}. Quando um evento é processado com sucesso, há a possibilidade de emitir uma notificação sobre isso, a qual é custosa devido ao fato de ser necessário rastreá-lo até o término de seu processamento \cite{Datatorrent}. 

Outra alternativa, é a de realizar o processamento em \textit{micro-batchs} (pequenos lotes) de eventos, tendo com uma das vantagens poder realizar operações em pequenos blocos de dados, em vez de individualmente, ao custo de introduzir um pequeno atraso no processo \cite{Datatorrent}.

\section{Apache Spark}
\label{sparkSection}

Apache Spark é uma plataforma de computação em \textit{cluster} (unidade lógica composta por um conjunto de computadores conectados entre si através da Rede, permitindo compartilhamento de recursos), com suporte a consultas a banco de dados, processamento de streaming (em \textit{Near Real Time}), grafos, e aprendizado de máquina. Tendo Java, Python e Scala como linguagens de programação suportadas \cite{Spark}.

A arquitetura do Spark, conforme a Fig. \ref{fig:sparkStack}, é composta por uma pilha integrando os seguintes componentes, a serem explicados posteriormente: Spark SQL, Spark Streaming, MLib, GraphX, Spark Core e Administradores de Cluster (Yarn \cite{Yarn} e Apache Mesos \cite{Mesos}). Tal estrutura, visa ser de fácil manutenção, teste, \textit{deploy}, e permitir aumento de perfomance do núcleo impactando seus demais componentes.

\begin{figure}[htb]
  \centering
    \includegraphics[width=0.5\textwidth]{Imagens/sparkStackImage.png}
  \caption{Ilustração da arquitetura em pilha do Apache Spark}
  {\bf Fonte:} \cite{LearningSpark}
  \label{fig:sparkStack}
\end{figure}

\subsection{Módulos do Apache Spark}

O Spark Core é o principal módulo do Apache Spark, responsável principalmente pelo gerenciamento de memória,  \textit{tasks} (conceito explicado em \ref{taskSection}) e tolerância a falha. Ainda nele, a abstração conhecida como  RDD (\textit{Resilient Distributed Datasets}) é definida, cujo papel é o de representar uma coleção de dados distribuídos e manipulados em paralelo. Os RDDs em Java são representados pela classe JavaRDD, criados através da classe JavaSparkContext (contexto da aplicação), que é instanciada recebendo como parâmetro um objeto SparkConf, contendo informações relacionadas ao nome da aplicação e o endereço em que ela será executada, pondendo ser local, ou, em cluster.

Outro módulo é o Spark Streaming, o qual realiza o processamento de dados em \textit{stream}. Os \textit{streams} são representados por uma sequência de RDDs, conhecida como DStream. O contexto de um \textit{streaming} (JavaStreamingContext) é criado usando as configurações da aplicação e o intervalo no qual cada DStream será definido. Após isso, tais \textit{streams} são atribuídos a um objeto da classe JavaReceiverInputDStream.

Além dos módulos detalhados nos parágrafos anteriores, é relevante mencionar o (i) Spark SQL, responsável por trabalhar com dados estruturados E consultas SQL; o (ii) MLib, relacionado ao aprendizado de máquina, contendo algorítimos tais como o de classificação, regressão, "clusterização", filtragem colaborativa, avaliação de modelo e importação de dados; e o (ii) GraphX, que é composto por uma biblioteca para manipulação de grafos e computações paralelas. Por fim, o Spark também possui um administrador de \textit{cluster} padrão, conhecido como \textit{Standalone Scheduler} \cite{Spark}, tendo também suporte ao YARN e Apache Mesos.

\subsection{Composição Interna do Apache Spark}
\label{sparkInternalsSection}

Nesta seção é explicada a composição interna do Apache Spark, expondo os componentes que permitem a execução distribuída de uma aplicação spark, tais como o Driver Program, Spark Context, Worker Node e Executor. Também, são explicados os conceitos sobre as operações de Transformação e Ação, e os relativos a \textit{Job}, \textit{Stage}, \textit{Task} e Partição RDD.

\subsubsection{Modelo de execução das aplicações Spark}
\label{sparkModelSection}

O modelo de execução das aplicações Spark é definido pela relação composta por um \textit{driver}, SparkContext, executors e \textit{tasks}, conforme ilustrado na Fig. \ref{fig:sparkComponents}. Nessa interação, as aplicações Spark funcionam num \textit{Worker Node} (qualquer nó capaz de de executar código de aplicação localmente ou num \textit{cluster}) como uma espécie de \textit{Driver}, o qual executa operações paralelas e define dados distribuídos sobre um \textit{cluster}. Além disso, o \textit{driver} é responsável por encapsular a função principal da aplicação e prover acesso ao Spark, utilizando o objeto da classe SparkContext. Tal objeto, é usado também para representar uma conexão com um \textit{cluster} e construir RDDs \cite{LearningSpark}. 

Após a construção de um RDD, é possível executar operações sobre ele. Essas operações são realizadas por \textit{executors}, processos administrados por uma aplicação Spark (cada aplicação tem os seus próprios \textit{executors}); nos quais há espaços reservados para execução de \textit{tasks} (conceito explicado na seção \ref{taskSection}). Há dois tipos de operações: (i) Ações (\textit{actions}) e (ii) Transformações (\textit{transformations}) \cite{Spark}. O primeiro tipo retorna um resultado ao \textit{driver} após computações sob um conjunto de dados, de acordo com uma função. Sendo o segundo, responsável por gerar novos conjuntos de dados (RDDs) através, também, de funções especificadas \cite{LearningSpark}. 

\begin{figure}[htb]
  \centering
    \includegraphics[width=0.5\textwidth]{Imagens/sparkComponentsImage.png}
  \caption{Componentes do Spark para execução distribuída}
  {\bf Fonte:} \cite{LearningSpark}
  \label{fig:sparkComponents}
\end{figure}

\subsubsection{Job}
\label{jobSection}

A abstração do conceito de \textit{job} está relacionada com o de \textit{action}. Mais especificamente, um \textit{job} é o conjunto de estágios (\textit{stages}) resultantes de uma determinada \textit{action}. Por exemplo, quando o método count() é invocado (para realizar a contagem de elementos dentro de um RDD), cria­-se um \textit{job} composto por um ou mais \textit{stages}. Os \textit{jobs}, por padrão, são escalonados para serem executados em ordem \abrv[FIFO -- First In, First Out]{FIFO (\textit{First In, First Out})}. Além disso, o \textit{scheduler} do Spark é responsável por criar um plano de execução física, o qual é utilizado para calcular as RDDs necessárias para executar a ação invocada \cite{LearningSpark}, \cite{SparkInternals}.

Em tal plano de execução física, defini­-se basicamente um grafo acíclico dirigido (DAG), relacionando as dependências existentes entre os RDDs, numa espécie de linhagem de execução (\textit{lineage}). Após isso, a partir da última RDD do último estágio, cada dependência é calculada, de trás para frente, para que posteriormente os RDDs dependentes possam ser calculados, até que todas as \textit{actions} necessárias tenham terminado \cite{LearningSpark}, \cite{SparkInternals}.

\subsubsection{Stage}
\label{stageSection}

A divisão de um \textit{job} resulta no conceito de \textit{stage}, ou seja, \textit{jobs} são compostos por um ou mais \textit{stages}, os quais têm  \textit{tasks} a serem executadas. Nem sempre a relação entre  stages e RDDs será de 1:1. No mais simples dos casos, para cada RDD há um \textit{stage}, sendo possível nos mais complexos haver mais de um \textit{stage} gerado por um único RDD \cite{LearningSpark}, \cite{SparkInternals}.

Por exemplo, havendo três RDDs no grafo RDD, não necessariamente haverão três \textit{stages}. Um dos motivos para isso acontecer é quando ocorre \textit{pipelining}, situação na qual é possível reduzir o número de  \textit{stages}, calculando os valores de alguns  RDDs  utilizando unicamente informações de seus antecessores, sem movimentação de dados de outros RDDs \cite{LearningSpark}, \cite{SparkInternals}.

Além da possibilidade do número de \textit{stages} ser reduzido, o contrário acontece quando fronteiras entre  \textit{stages} são definidas. Tal situação, ocorre porque algumas transformações, como a reduceByKey (função de agregação por chaves), podem resultar em reparticionamento do conjunto de dados para a computação de alguma saída, exigindo dados de outros RDDs para a formação de um único RDD. Assim, em cada fronteira entre os \textit{stages}, \textit{tasks} do estágio antecessor são responsáveis por escrever dados para o disco e buscar \textit{tasks} no estágio sucessor, através da rede, resultando em um processo custoso, conhecido como shuffling \cite{LearningSpark}, \cite{SparkInternals}.

O número de partições entre o estágio predecessor e sucessor pode ser diferente, sendo possível customizá-lo, embora isso não seja recomendável. Tal aconselhamento é devido ao fato de que se o número for modificado para uma pequena quantidade de partições, tais podem sofrer com \textit{overloaded tasks}  (sobrecarregadas), do contrário, havendo partições em excesso, resultará em um alto número de \textit{shuffling} entre elas \cite{LearningSpark}, \cite{SparkInternals}.

Em resumo, \textit{shuffling} sempre acontecerá quando for necessário obter dados de outras partições para computar um resultado, sendo esse um procedimento custoso devido ao número de operações de entrada e saída envolvendo: leitura/escrita em disco e transferência de dados através da rede. No entanto, se necessário, o Spark provê uma forma eficiente para reparticionamento, conhecida como coalesce(), a qual reduz o número de partições sem causar movimentação de dados \cite{LearningSpark}.

\subsubsection{Task}
\label{taskSection}

A abstração do conceito \textit{task} está relacionada principalmente com \textit{stage}, pois, uma vez que os estágios são definidos, \textit{tasks} são criadas e enviadas para um \textit{scheduler} interno. Além disso, \textit{tasks} estão muito próximas da definição de partition, pelo fato de ser necessária a existência de uma task para cada partition, para executar as computações necessárias sobre ela \cite{LearningSpark}.

Portanto, o número de \textit{tasks} em um stage é definido pelo número de partições existentes no RDD antecessor. E, por outro lado, o número de partições em um determinado RDD é igual ao número de partições existentes no RDD do qual ele depende. No entanto, há exceções em caso de (i) \textit{coalescing}, processo o qual permite criar um RDD com menos partições que seu antecessor; (ii) união, sendo o número de partições resultado da soma do número de partições predecessoras; (iii) produto cartesiano, produto dos predecessores \cite{LearningSpark}.

Cada \textit{task} internamente é divida em algumas etapas, sendo elas: (i) carregamento dos dados de entrada, sejam eles provenientes de unidades de armazenamento (caso o RDD seja um RDD de entrada de dados), de um RDD existente (armazenado em memória cache), ou, de saídas de outro RDD (processo de \textit{shuffling}), (ii) processamento da operação necessária para computação do RDD representado por ela, (iii) escrever a saída para o processo de \textit{shuffling}, para um armazenamento externo ou para o \textit{driver} (caso seja o RDD final de uma ação). Em resumo, uma  textit{task} é responsável por coletar os dados de entrada, processá-­los e, por fim, gerar uma saída \cite{LearningSpark}.

\section{Apache Storm}
\label{stormSection}

Apache Storm \cite{Storm} é uma plataforma de computação em \textit{cluster}, com suporte a processamento de \textit{stream}  de dados em tempo real. O Storm requer pouca manutenção, é de fácil de administração e tem suporte a qualquer linguagem de programação (que leia e escreva fluxos de dados padronizados), posto que em seu núcleo é utilizado o Apache Thrift \cite{Thrift} (framework que permite o desenvolvimento de serviços multilinguagem) para definir e submeter topologias (conceito definido em \ref{topologySection}) \cite{Storm}.

A arquitetura do Storm, conforme a Fig. \ref{fig:stormComponents}, é composta pelos seguintes componentes, a serem explicados posteriormente: Nimbus, ZooKeeper e Supervisor Node.

\begin{figure}[htb]
  \centering
    \includegraphics[width=0.5\textwidth]{Imagens/stormComponentsImage.png}
  \caption{Ilustração da arquitetura do Apache Storm}
  {\bf Fonte:} \cite{LearningStorm}
  \label{fig:stormComponents}
\end{figure}

\subsection{Composição interna do Apache Storm}

Nesta seção é explicada a composição interna do Apache Storm, expondo os principais componentes que permitem a execução distribuída de uma topologia Storm, tais como o Nimbus, ZooKeeper e \textit{Supervisor Nodes}.

\subsubsection{Nimbus}
\label{nimbusSection}

Nimbus é o processo \textit{master} executado num \textit{cluster} Storm, tendo ele uma única instância e sendo responsável por distribuir o código da aplicação (\textit{job}) para os nós \textit{workers} (computadores que compõem o \textit{cluster}), aos quais são atribuídas \textit{tasks} (parte de um \textit{job}). As \textit{tasks} são monitoradas pelo \textit{Supervisor Node}, sendo reiniciadas em caso de falha e quando requisitado. Ainda, caso um \textit{Supervisor Node} falhe continuadamente, o job é atribuído para outro nó \textit{worker} \cite{LearningStorm}, \cite{StormPython}. 

O Nimbus utiliza um protocolo de comunicação sem estado (\textit{Stateless Protocol}), ou seja, cada requisição é tratada individualmente, sem relação com a anterior, não armazenando dados ou estado, sendo assim todos os seus dados são armazenados no ZooKeeper (definido em \ref{zookeeperSection}). Além disso, ele é projetado para ser \textit{fail­-fast}, ou seja, em caso de falha é rapidamente reiniciado, sem afetar as \textit{tasks} em execução nos nós  \textit{workers} \cite{LearningStorm}, \cite{StormPython}.

\subsubsection{Supervisor Node}
\label{supervisorSection}

Cada \textit{Supervisor Node} é responsável pela administração de um determinado nó do \textit{cluster} Storm; gerenciando o ciclo de vida de processos \textit{workers} relacionados a execução das \textit{tasks} (partes de uma topologia) atribuídas a ele próprio. Os workers quando em execução emitem "sinais de vida" (\textit{heartbeats}), possibilitando o \textit{supervisor} detectar e reiniciar caso não estejam respondendo. E, assim como o Nimbus, um \textit{Supervisor Node} é projetado para ser  \textit{fail­-fast} \cite{LearningStorm}, \cite{StormPython}.

\subsubsection{ZooKeeper}
\label{zookeeperSection}

O ZooKeeper Cluster \cite{ZooKeeper} é responsável por coordenar processos, informações compartilhadas, \textit{tasks} submetidas ao Storm e estados associados ao \textit{cluster}, num contexto distribuído e de forma confiável, sendo possível aumentar o nível de confiabilidade tendo mais de um servidor ZooKeeper. O ZooKeeper atua também como o intermediário da comunicação entre Nimbus e os \textit{Supervisor Nodes}, pois eles não se comunicam diretamente entre si, ambos também podem ser finalizados sem afetar o \textit{cluster}, visto que todos os seus dados, são armazenados no ZooKeeper, como já mencionado anteriormente \cite{LearningStorm}, \cite{StormPython}.

\subsubsection{Topologia}
\label{topologySection}

A topologia Storm, ilustrada na Fig. \ref{fig:stormTopology}, é uma abstração que define um grafo acíclico dirigido (DAG), utilizado para computações de \textit{streams}. Cada nó desse grafo é responsável por executar algum processamento, enviando seu resultado para o próximo nó do fluxo. Após definida a topologia, ela pode ser executada localmente ou submetida a um \textit{cluster} \cite{LearningStorm}, \cite{StormPython}.

\textit{Stream} é um dos componentes da topologia Storm, definido como uma sequência de tuplas independentes e imutáveis, fornecidas por um ou mais \textit{spout} e processadas por um ou mais \textit{bolt}. Cada \textit{stream} tem o seu respectivo ID, que é utilizado pelos \textit{bolts} para consumirem e produzirem as tuplas. As tuplas compõem uma unidade básica de dados, suportando os tipos de dados (serializáveis) no qual a topologia está sendo desenvolvida.

\begin{figure}[htb]
  \centering
    \includegraphics[width=0.5\textwidth]{Imagens/stormTopologyImage.png}
  \caption{Ilustração de uma topologia do Storm}
  {\bf Fonte:} \cite{LearningStorm}
  \label{fig:stormTopology}
\end{figure}

\paragraph{Bolt.} Os \textit{bolts} são unidades de processamento de dados (\textit{streams}), sendo eles responsáveis por executar transformações simples sobre as tuplas, as quais são combinadas com outras formando complexas transformações. Também, eles podem ser inscritos para receberem informações tanto de outros \textit{bolts}, quanto dos \textit{spouts}, além de produzirem \textit{streams} como saída \cite{LearningStorm}.

Tais \textit{streams} são declarados, emitidos para outro \textit{bolt} e processados, respectivamente, pelos métodos declareStream, emit e execute. As tuplas não precisam ser processadas imediatamente quando chegam a um \textit{bolt}, pois, talvez haja a necessidade de aguardar para executar alguma operação de junção (\textit{join}) com outra tupla, por exemplo. Também, inúmeros métodos definidos pela interface Tuple podem recuperar meta­dados associados com a tupla recebida via execute \cite{LearningStorm}.

Por exemplo, se um ID de mensagem está associado com uma tupla, o método execute deverá publicar um evento \textit{ack}, ou, \textit{fail}, para o \textit{bolt}, caso contrário o Storm não tem como saber se uma tupla foi processada. Sendo assim, o \textit{bolt} envia automaticamente uma mensagem de confirmação após o término da execução do método execute e, em caso de um evento de falha, é lançada uma exceção \cite{LearningStorm}.

Além disso, num contexto distribuído, a topologia pode ser serializada e submetida, via Nimbus, para um \textit{cluster}. No qual, será processada por \textit{worker nodes}. Nesse contexto, o método prepare pode ser utilizado para assegurar que o \textit{bolt} está, após a desserialização, configurado corretamente para executar as tuplas \cite{LearningStorm}, \cite{StormPython}.

\paragraph{Spout.} Na topologia Storm um \textit{Spout} é o responsável pelo fornecimento de tuplas, as quais são lidas e escritas por ele utilizando uma fonte externa de dados \cite{LearningStorm}. 

As tuplas emitidas por um  \textit{spout} são rastreadas pelo Storm até terminarem o processamento, sendo emitida uma confirmação ao término dele. Tal procedimento somente ocorre se um ID de mensagem foi gerado na emissão da tupla e, caso esse ID tenha sido definido como nulo, o rastreamento não irá acontecer \cite{LearningStorm}.

Outra opção é definir um \textit{time­out} a topologia, sendo dessa forma enviada uma mensagem de falha para o  \textit{spout},  caso a tupla não seja processada dentro do tempo estipulado. Sendo necessário, novamente, definir um ID de mensagem. O custo dessa confirmação do processamento ter sido executado com sucesso é a pequena perda de \textit{performance}, que pode ser relevante em determinados contextos; devido a isso é possível ignorar a emissão de IDs de mensagens
\cite{LearningStorm}.

Os principais métodos de um \textit{spout} são: o open(), executado quando o \textit{spout} é inicializado, sendo nele definida a lógica para acesso a dados de fontes externas; o de declaração de \textit{stream} (declareStream) e o de processamento de próxima tupla (nextTuple), que ocorre se houver confirmação de sucesso da tupla anterior (ack), sendo o método fail chamado pelo Storm caso isso não ocorra \cite{LearningStorm}.

Por fim, nenhum dos métodos utilizados para a construção de um  \textit{spout} devem ser bloqueantes, pois o Storm executa todos os métodos numa mesma \textit{thread}. Além disso, todo  \textit{spout} tem um \textit{buffer} interno para o rastreamento dos status das tuplas emitidas, as quais são mantidas nele até uma confirmação de processamento concluído com sucesso (ack) ou falha (fail); não sendo inseridas novas tuplas (via nextTuple) no \textit{buffer} quando ele esá cheio \cite{LearningStorm}.

\section{Processamento de Linguagem Natural}

O Processamento de Linguagem Natural (NPL, \textit{Natural Processing Language}) pode ser definido como uma sequência de computações, divididas em estágios, objetivando entender o significado de determinado texto.  Tal atividade é demasiadamente complexa, por ser dependente do conjunto de caracteres (\textit{charsets}) sendo processados (relacionados com o idioma), do sistema de escrita, do domínio da aplicação, etc \cite{NplBook}. Devido a essa complexidade, a metodologia clássica se divide normalmente nas seguintes fases (ilustradas na Fig. \ref{fig:nlpStages}): \textit{Tokenization}, \textit{Lexical analysis}, \textit{Syntactic analysis}, \textit{Semantic analysis} e \textit{Pragmatic analysis} \cite{NplBook}.

Na fase \textit{Tokenization}, ocorre a extração das palavras que compõem o texto, realizada através da indentificação dos espaços existentes entre cada palavra. Nos idiomas derivados do Latim, como no caso do Português, tal estratégia pode ser aplicada, pois o sistema de escrita separa as palavras utilizando espaços entre elas (\textit{space-delimited}), sendo abordadas outras técnicas de extração para as linguagens não segmentadas \cite{NplBook}. Ainda nessa fase, ocorre a segmentação do texto, ou seja, a divisão dos períodos existentes, na qual precisam ser consideradas questões relacionadas a presença de pontuações e símbolos \cite{NplBook}.

Em \textit{Lexical analysis}, uma das atividades é a de relacionar variações morfológicas de uma palavra com seu respectivo lema (a forma mais abstrata de uma palavra, sem flexões de gênero, derivações, etc) \cite{NplBook}. Sendo assim é possível reduzir a quantidade de palavras em processamento, criar \textit{parsers} (conversores) entre morfologias e lemas, e vice-versa \cite{NplBook}.

Continuando, a fase seguinte é a \textit{Syntactic analysis}, responsável pela descrição estrutural das palavras de acordo com uma gramática formal \cite{NplBook}. Um dos conceitos que se pode atribuir a esse estágio é o de \abrv[POS -- Part-of-speeach]{POS,\textit{Part-of-speeach}}, no qual são atribuídas as classes gramáticais (verbo, adjetivo, artigo, pronome, nome, etc.) de cada palavra, considerando para isso questões relacionadas a ambiguidades, contexto a palavra está inserida, etc. \cite{SmartCityInitiative}, \cite{NplBook}. 

Ao final do estágio anteriormente mencionado, os resultados dele são utilizadas na fase \textit{Semantic analysis}. Nela, as palavras são analisadas buscando entender seus respectivos significados, corrigir expressões, sentenças, levando em consideração o contexto no qual estão inseridas \cite{NplBook}. Sendo assim, são realizadas traduções para uma meta-linguagagem, objetivando viabilizar essas analizes \cite{NplBook}. Por fim, o estágio \textit{Pragmatic analysis}, encontra-se como o último do fluxo de Processamento de Linguagem Natural, no qual acontece a análise das possíveis intenções expressas numa sentença \cite{NplBook}. 

\begin{figure}[htb]
  \centering
    \includegraphics[width=0.3\textwidth]{Imagens/pnl.png}
  \caption{Estágios de um Processamento de Linguagem Natural}
  {\bf Fonte:} \cite{NplBook}
  \label{fig:nlpStages}
\end{figure}

\section{Aplicações Web e Web Services}

A criação de Tim Berners-Lee, conhecida como \abrv[WWW -- World Wide Web]{\textit{World Wide Web} (WWW)}, inicialmente permitiu o compartilhamento de documentos científicos, via terminais \cite{WebApplicationArchitecture}. Isso foi possível, através de \textit{Web servers}, ou seja, computadores responsáveis por compartilhar recursos com os demais conectados à Internet \cite{WebApplicationArchitecture}. 

Posteriormente, as páginas \textit{web} (\textit{Web Pages}) foram criadas, disponibilizando uma interface estática, construída em \abrv[HTML -- HyperText Markup]{HTML (\textit{HyperText Markup})}, para visualização dos documentos compartilhados através da Web \cite{WebApplicationArchitecture}. Após isso, houve também o surgimento dos Web Sites, definidos como uma coleção de \textit{web pages}, estruturadas, levando em consideração aspectos relacionados à estética e identidade (\textit{look and feel}), arquitetura do conteúdo, etc. \cite{WebApplicationArchitecture}.

Apesar disso, mesmo com os \textit{web sites}, a informação continuava estática.  Com isso, as aplicações web surgiram para viabilizar conteúdos dinâmicos, contruídos através de parâmetros enviados pelo usuário \cite{WebApplicationArchitecture}. Tais parâmetros, são informados por meio de uma interface web de um navegador (cliente), que por sua vez é responsável por enviar requisições ao servidor, utilizando protocolos da Internet, como o \abrv[HTTP -- Hypertext Transfer Protocol]{HTTP (\textit{Hypertext Transfer Protocol})} \cite{WebApplicationArchitecture}. Os componentes mencionados, dentre outros, são ilustrados na Fig. \ref{fig:webAppArchitecture}.

\begin{figure}[htb]
  \centering
    \includegraphics[width=0.7\textwidth]{Imagens/webAppArchitecture.png}
  \caption{Arquitetura de uma Aplicação Web}
  {\bf Fonte:} \cite{WebApplicationArchitectureGuide}
  \label{fig:webAppArchitecture}
\end{figure}

Na Fig. \ref{fig:webAppArchitecture}, o lado do \textit{client} (cliente) é composto pelo navegador (\textit{browser}), que é responsável pela renderização da página HTML e comunicação com o \textit{Web Server}. Sendo a camada do Web Server, por sua vez, composta pelos componentes relacionados a Interface de Usuário e ao processamento dela (\textit{User Interface \abrv[UI -- User Interface]{(UI)} Components} e \textit{Process Components}). 

As demais camadas são: \textit{Business}, contendo uma interface (\textit{Application Facade}) para acesso as regras de négocio da aplicação (\textit{Business Workflows}), componentes (\textit{Business Components}) e entidades (\textit{Business Entities}); \textit{Data}, fornecendo acesso componentes para acesso aos dados (\textit{Data Access Components}), utilitários (\textit{Data Helpers / Utilities}) e agentes de serviço (\textit{Service Agents}); \textit{Cross-Cutting}, compondo os serviços transversais relacionados a Segurança (\textit{Security}), Administração Operacional (\textit{Operational Management}) e Comunicação (\textit{Communication}). 

Continuando, ainda há duas camadas, a do servidor de banco de dados (\textit{Database Server}) e a de serviços (\textit{Services}). Na de serviços, é possível expor os serviços da aplicação para outras existentes ou mesmo consumir delas, através de \textit{Web Services}. Os \textit{Web Services} são aplicações \textit{web} distribuídas onde o cliente é uma outra aplicação, existindo duas principais formas de implementá-las: (i) \abrv[REST -- Representational State Transfer]{Representational State Transfer (REST)} e (ii) [SOAP -- Simple Object Access Protocol]{\textit{Simple Object Access Protocol} (SOAP)} \cite{WebApplicationArchitectureGuide}.

A primeira delas, REST, defini-se como um padrão arquitetural composto por verbos do protocolo HTTP (GET, POST, PUT e DELETE), através dos quais podem ser realizadas requisições aos serviços existentes, acessíveis via \textit{endpoints} \abrv[URI -- Uniform Resource Identifier]{(URIs, \textit{Uniform Resource Identifier})} \cite{WebApplicationArchitectureGuide}. A segunda, SOAP, disponibiliza uma WSDL (\textit{Web Services Definition Language}), especificando como determinado serviço deve acessado, expondo através dela informações como: nome do serviço, métodos disponíveis, e seus respectivos argumentos e tipos de dados.

Utilizando SOAP, é necessário lidar com XML, formato no qual a WSDL é contruída, tendo como vantagem a possibilidade de utilizar outros protocolos além do HTTP \cite{WebApplicationArchitectureGuide}. Ao contrário do SOAP, REST tem a sua fundamentação no protocolo HTTP e devido a isso não mamtém estado, ou seja, as requisições precisam conter todas as informações necessárias para ser executada \cite{WebApplicationArchitectureGuide}. 
