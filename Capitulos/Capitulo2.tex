% Fundamentação Teórica
\chapter{Fundamentação Teórica}
\label{chapter2}

Nesse capítulo, são apresentados os conceitos relacionados a essa monografia, os quais estão divididos nas seguintes seções: \ref{smartCities}, sobre a temática de Cidades Inteligentes; \ref{realTimePlatforms}, a respeito de Plataformas de processamento em tempo real; \ref{sparkSection} e \ref{stormSection}, sobre o Apache Spark e Storm, respectivamente. 

\section{Cidades Inteligentes}
\label{smartCities}

Projeções da Organização das Nações Unidas \abrv[ONU --­ Organização das Nações Unidas]{(ONU)}, indicam que a população mundial urbana atual passará de 3.9 bilhões de pessoas para 6.3 bilhões em 2050, representando 66\% do total de habitantes, 9.54 bilhões \cite{OnuArticle}. Tal crescimento populacional tem tido consequências graves como a miséria; sendo pertencente a classe de problemas de solução não técnica, de acordo com o fenômeno conhecido por Tragédia dos Comuns, no qual uma alta demanda de recursos finitos (água, energia, alimentos, estradas, etc.) os tornam escassos \cite{TragedyOfTheCommons}.

A ONU, por sua vez, indicam algumas estratégias políticas para lidar com esse problema, tais como: incentivo a migração interna; redistribuição espacial da população; expansão da infraestrutura; garantia de acesso a serviços e oportunidades de trabalho; uso de Tecnologias da Informação e Comunicação \abrv[TICs --­ Tecnologias da Informação e Comunicação]{(TICs)}, para melhoraria na entrega de serviços \cite{OnuArticle}, etc. Podendo nesse último ponto, por exemplo, haver exploração das TICs visando a implantação de iniciativas relacionadas a Cidades Inteligentes. 

As Cidades Inteligentes são locais nos quais, principalmente, busca-se transformar os sistemas da cidade e otimizar o uso de seus recursos finitos, melhorando assim a eficiência da economia, possibilitando desenvolvimento político, social, cultural e urbano \cite{AVisionOfSocialMedia}. Apesar dessas possíveis transformações e otimizações, é importante salientar, novamente, que nenhuma abordagem técnica resolve por si só as problemáticas decorrentes do crescimento populacional \cite{TragedyOfTheCommons}.

Uma das problemáticas que as Cidades Inteligentes ajudam a resolver é a de demanda por eficiência energética (decorrente das mudanças climáticas), que requer das cidades menos emissão de gás carbono, podendo isso ser obtido utilizando iluminação pública, com investimentos em prédios sustentáveis (energeticamente sustentável e com uso de áreas verdes), transportes públicos e ciclovias. Outro possibilidade, é o de desenvolvimento de serviços digitais capazes de ajudar os cidadãos com questões cotidianas, como achar um táxi, saber a localização de um ônibus, encontrar a rota com menos congestionamento de carros, reportar crimes, comunicar-se com o governo, etc.

O problema relacionado a Cidades Inteligentes tratado por essa monografia, como já mencionado, insere-se no contexto de processamento de grande volume de dados, o qual é devido, principalmente a conexão de objetos conectados à Internet (contexto de IoT, conceito explicado em \ref{iotSection}), com previsão de existirem 212 bilhões até 2020. E, também, ao aumento do número de pessoas conectas (o que com o crescimento populacional tende a aumentar), prevendo-se 3.5 bilhões em 2017, sendo 64\% via dispositivos móveis \cite{CiscoArticle}.

Ainda, mais especificamente, espera-se que a quantidade de dados existentes dobre a cada dois anos até 2020 \cite{EmcArticle2}. Outros fatores que tem contribuído para isso são: o crescimento do uso da Internet, smartphones e Redes Sociais; a queda do custo de equipamento para criar, capturar, administrar, proteger e armazenar informação; migração da TV analógica para a digital; crescimento dos dados gerados por máquinas, incluindo imagens de câmeras de segurança e da informação sobre informação \cite{CiscoArticle}.

\subsection{Internet das Coisas}
\label{iotSection}

Considerando o exposto pela seção \ref{smartCities}, a expansão de pessoas e coisas conectadas à Internet, chegar­-se-­á um patamar em que tudo o que é possível estar, estará conectado, ampliando o conceito de Internet das Coisas para o de Internet de Todas as Coisas, segundo a Cisco \cite{CiscoIoE}. Em tal cenário, cerca de 44 trilhões de gigabytes serão gerados \cite{EmcArticle2}, os quais processados por sistemas inteligentes, ajudarão no surgimento de serviços de grande impacto no cotidiano de uma cidade \cite{CiscoArticle}.

Principalmente, aqueles que monitoram e reportam continuadamente qualquer modificação que ocorra em um determinado cenário. Por exemplo, no contexto de saúde pública, é possível monitorar as condições do organismo de um paciente, notificando os médicos responsáveis caso a pessoa esteja em risco, através de uma rápida comunicação e resposta a tal acontecimento. Alguns dos sistemas semelhantes a esse são exemplificados na Fig. \ref{fig:iotImage}.

\begin{figure}[htb]
  \centering
    \includegraphics[width=1\textwidth]{Imagens/iotImage.png}
  \caption{Cidade num invólucro digital}
  {\bf Fonte:} \cite{CiscoArticle}
  \label{fig:iotImage}
\end{figure}

Na Fig. \ref{fig:iotImage}, organizações, pessoas e objetos estão conectados, criando um invólucro digital, composto por representações de serviços conectados a nuvem, tais como: o de um (i) Hospital Inteligente, conectado a dispositivos médicos inteligentes e a ambulâncias; (ii) Centro Digital de Controle e Comando Municipal, integrado a um sistema inteligente de segurança pública e armazenamento de dados; (iii) Sistema de Otimização de Fluxo de Tráfico, conectado a um sistema de estradas inteligentes agregadas a câmeras de controle de tráfico; (iv) Fábrica Inteligente, integrada a um sistema de otimização de logística e fábrica; (v) Administração de Energia Doméstica e (vi) Smart Grid (um novo modelo de Redes Elétricas \cite{IeeeArticle}) e (vii) Otimização de Rede de Comunicação.

Tais serviços não serão estudados nesse trabalho, foram apenas referenciados visando demonstrar uma pequena parte da gama de possibilidades existentes em Cidades Inteligentes, Internet das Coisas, e a problemática relacionada ao processamento de dados.

\subsection{Requisitos de uma aplicação de Cidade Inteligente}

Ante a variedade de fontes de dados disponíveis, conforme mencionado na seção \ref{iotSection}, a capacidade de processar grandes volumes de dados pode ser um dos requisitos necessários a uma aplicação de Cidade Inteligente. Normalmente, duas métricas são utilizadas para analisar esse requisito: os valores de (i) throughput e (ii) latência. O primeiro termo se refere a taxa de processamento \cite{Techopedia} e, o segundo a variação do tempo entre um estímulo e resposta \cite{Techopedia}.

Dependendo do contexto da aplicação, o valor da latência tem maior relevância sob o de throughput. Por exemplo, a latência talvez seja mais interessante de ser priorizada quando respostas a determinados eventos precisam ser no menor intervalo de tempo possível (menos de um segundo). Por outro lado, as aplicações que priorizam throughput, podem apenas necessitarem processar grandes volumes de dados dentro de um valor de latência aceitável (no máximo alguns segundos).

Outro requisito importante, é o de tolerância a falhas (necessário quando a aplicação está inserida em ambientes distribuídos, ou, de incertezas), o qual permite o funcionamento do sistema mesmo que uma falha ocorra, o que pode ser obtido, por exemplo, por meio de replicação \cite{SistemasDistribuidos}. Além disso, pode existir a necessidade de antender o requisito de escalabilidade, através do qual é possível oferecer um serviço de alta qualidade conforme o aumento da demanda, adicionando novos recursos (escalabilidade horizontal), ou, melhorando os existentes (escalabilidade vertical) \cite{Sommerville}.

Além disso, a aplicação pode precisar do requisito de processamento em tempo real, no qual há um limite de tempo pré-determinado para as respostas aos eventos do sistema \cite{Sommerville}. Por fim, é importante também avaliar as ferramentas que serão utilizadas no desenvolvimento da aplicação quanto ao suporte aos requisitos citados e as abstrações que elas dispõem.

\subsection{e-Participação}

Uma das temáticas abordadas em Cidades Inteligentes, é a de promover novos meios para a participação do cidadão com questões relaciondas a gestão da cidade \cite{AVisionOfSocialMedia}. Essa interação pode ser feita através de Redes Sociais, que são compostas por um conjunto de pessoas (ou, organizações), representando nós de uma rede, sendo a conexão entre eles conhecida como relacionamento \cite{DccArticle}. 

Sendo assim, tal ambiente virtual, tem proporcionado um novo espaço para que os cidadãos possam participar de processos de consulta e deliberação (exame e dicussão de um assunto \cite{Priberam}), atuando com os governos como atores de processos de tomadas de decisão \cite{DccArticle}. Além das Redes Sociais, a participação pode ocorrer em outros ambientes virtuais, tais como aplicativos, wiki, fórum, blogs, dentre outros \cite{AnpocsArticle}, resumindo-se em e-participação, conceito inserido no de Governo Eletrônico. 

O Governo Eletrônico é caracterizado pelo uso de TICs pelo governo público, buscando prover melhores serviços, informações e conhecimento ao cidadão; facitando o acesso ao processo político e incentivando a participação \cite{AnpocsArticle}. Ele pode ser dividido, principalmente, nos três campos seguintes: e-Administração, a respeito do funcionamento interno do poder público; e-Governo, no tocante a entrega e fornecimento de serviços e informações qualificadas aos cidadãos; e-Democracia, relacionada a ampliação da participação da sociedade na tomada de decisão, sendo a e-Participação uma subárea desse último \cite{AnpocsArticle}.

A intenção da e-Participação é reforçar e renovar as interações entre o setor público, os políticos e cidadãos; tanto quanto possível no processo democrático \cite{AnpocsArticle}. Além disso, a e-Participação não pode ser avaliada somente por seus aspectos técnicos, mas também quanto a capacidade de incrementar a democracia \cite{AnpocsArticle}.

Um dos desafios nessa área é avaliar as ferramentas apoiadas pelas TICs, quanto as formas de engajamento existentes, como informação, consulta, ou, participação ativa \cite{AnpocsArticle}. Ainda, segundo citação contida em \cite{AnpocsArticle}, a e-Participação é um conjunto de várias tecnologias, medidas sociais e políticas, havendo a necessidade de melhorar a compreensão das relações entre esses componentes e como suas respectivas práticas de avaliação podem ser aplicadas a e-Participção como um todo.

Com isso, para que os processos que a envolvem sejam eficazes é importante considerar os ambientes online e off-line, ou seja, incrementando os métodos tradicionais (conferências, fóruns, conselhos, ouvidorias, audiências, consultas, reuniões, comitês, grupos de trabalho e mesas de negociação) com as possibilidades da e-Particição, estendendo-a ainda aos grupos desfavorecidos e desconectados \cite{AnpocsArticle}. Por fim, no parágrafo seguinte, são referenciados alguns dos diferentes níveis de e-Participação.   

\paragraph{Níveis de e-Participação.} No nível e-Informação, há um canal unidirecional, visando apenas fornecer informações de interesse cívico; no de e-Consulta, a comunicação é biderecional, via coleta de opiniões e alternativas; no de e-Envolvimento busca-se garantir a compreensão e levar em consideração os anseios do cidadão; em e-Colaboração, a comunicação é bidirecional, e o cidadão participa ativamente no desenvolvimento de alternativas e indentificação de melhores soluções; por fim, no de e-Empoderamento, a influência, controle e elaboração de políticas pelo e para o público é viabilizada \cite{AnpocsArticle}. 

\section{Plataformas de processamento em tempo real}
\label{realTimePlatforms}

As plataformas de processamento em tempo real \abrv[RTC --­ Real­ Time Computing]{(RTC, Real­ Time Computing)}, compostas por hardware ou software, são sistemas que tem como um dos principais requisitos emitir respostas a eventos de acordo com um determinado deadline (limite de tempo). Sendo assim, a corretude da computação não depende apenas da corretude lógica, mas também dos resultados serem produzidos de acordo com o deadline especificado \cite{RtcAsNewDiscipline}, \cite{Sommerville}.

Normalmente, os resultados são obtidos através de processamentos realizados por um conjunto de tasks (tarefas) cooperativas, iniciadas por eventos do sistema. Os eventos são dependentes do ambiente no qual estão inseridos, podendo ocorrer periodicamente (de forma regular e previsível), ou, aperiodicamente (irregulares e imprevisíveis) \cite{RtcAsNewDiscipline}, \cite{Sommerville}.

As tasks podem ter uma relação de interdependência e ao mesmo tempo nem todos os eventos que as originaram necessitarem de ser processados dentro de um deadline. Apesar disso, nenhuma task pode vir a comprometer o processamento de outra \cite{RtcAsNewDiscipline}.  

Com isso, os deadlines podem ser classificados em hard, firm, ou, soft. No primeiro caso, respectivamente, as respostas a todos os eventos devem necessariamente ocorrer dentro do  deadline  definido; no segundo, deadlines esporadicamente não atendidos são aceitos; no terceiro, deadlines não alcançados são permitidos frequentemente \cite{RtcAsNewDiscipline}. Além desses categorias, há os sistemas com delay (atraso) introduzido entre o intervalo de tempo de estímulo e resposta, os quais são classificados como near real time (NRT), ou seja, são sistemas de processamento em "quase tempo real".

Sendo assim, na categoria hard, é considerado como falha se o tempo estimado para um processamento não for atendido, e nas demais, a ocorrência disso resulta numa degradação (contínua de acordo com a quantidade de deadlines não atendidos) \cite{RtcAsNewDiscipline}, \cite{Sommerville}.

Entende-se por falha quando o usuário não recebe algo esperado (por exemplo, deadline não atendido) devido a um erro de sistema. Sendo esse erro um estado errôneo resultante de um defeito (característica do sistema que pode resultar em erro). E, degradação, como decréscimo da qualidade (conceito subjetivo, de acordo com os requisitos da aplicação) do sistema \cite{Sommerville}.

Por fim, é importante mencionar também que uma falha de sistema pode comprometer o requisito de Confiança e prejudicar um grande número de pessoas \cite{RtcAsNewDiscipline}, \cite{Sommerville}. Na Fig. \ref{fig:reliabilityDiagram} a seguir, são ilustradas as principais propriedades desse requisito:

\begin{figure}[htb]
  \centering
    \includegraphics[width=1\textwidth]{Imagens/reliabilityDiagram.png}
  \caption{Principais propriedades de Confiança}
  {\bf Fonte:} \cite{Sommerville}
  \label{fig:reliabilityDiagram}
\end{figure}

\subsection{Processamento de fluxo de eventos em tempo real}
\label{espSubsection}

Fluxo (ou stream) de eventos, basicamente, pode ser entendido como uma série de eventos em função do tempo \cite{Datatorrent}, \cite{Complexevents}. Dentro desse escopo, duas abordagens de processamento são importantes diferenciar: \abrv[ESP -- Event Stream Processing]{(i) ESP (Event Stream Processing, ou, Processamento de Fluxo de Eventos)} e \abrv[CEP -- Complex Event Processing]{(ii) CEP (Complex Event Processing, ou, Processamento Complexo de Eventos)}. A primeira, costuma-se focar principalmente com questões de baixo nível, relacionadas a como processar eventos em tempo real atendendo requisitos de escalabilidade, tolerância a falha, confiabilidade, etc \cite{ConfluentArticle}.

Na segunda abordagem, os streams são utilizados para criar uma nuvem de eventos, parcialmente ordenados por tempo e causalidade, conceito conhecido como \abrv[POSET -- Partially ordered set of events]{POSET (Partially ordered set of events)} \cite{Complexevents}. Sendo assim, normalmente, visa-se trabalhar questões de alto nível, utilizando posets para a criação de padrões de eventos, envolvendo seus relacionamentos, estrutura interna, etc. Com esse conjunto de informações é possível compor eventos complexos, os quais podem ser consultados continuadamente \cite{ConfluentArticle}. 

Portanto, nessa monografia, será utilizada a primeira abordagem (ESP) para processamento de eventos, por ser mais adequada ao objetivo proposto no Cap. \ref{chapter1}. Em ESPs, algumas plataformas processam os streams continuadamente conforme são recebidos pelo sistema; paradigma conhecido como One at time. Quando um evento é processado com sucesso, há a possibilidade de emitir uma notificação sobre isso, a qual é custosa por ser necessário rastreá-lo até o término de seu processamento \cite{Datatorrent}. 

Outra alternativa, é a de realizar o processamento em micro-batchs (pequenos lotes) de eventos, tendo com uma das vantagens poder realizar operações em pequenos blocos de dados, em vez de individualmente, ao custo de introduzir um pequeno atraso no processo \cite{Datatorrent}.

\section{Apache Spark}
\label{sparkSection}

Apache Spark é uma plataforma de computação em cluster (unidade lógica composta por um conjunto de computadores conectados entre si através da Rede, permitindo compartilhamento de recursos \cite{Techopedia}), com suporte a consultas a banco de dados, processamento de streaming (em near real time), grafos, e aprendizado de máquina. Tendo Java, Python e Scala como linguagens de programação suportadas \cite{Spark}.

A arquitetura do Spark, conforme a Fig. \ref{fig:sparkStack}, é composta por uma pilha integrando os seguintes componentes, a serem explicados posteriormente: Spark SQL, Spark Streaming, MLib, GraphX, Spark Core e Administradores de Cluster (Yarn \cite{Yarn} e Apache Mesos \cite{Mesos}). Tal estrutura visa ser de fácil manutenção, teste, deploy, e permitir aumento de perfomance do núcleo impactando seus demais componentes.

\begin{figure}[htb]
  \centering
    \includegraphics[width=0.5\textwidth]{Imagens/sparkStackImage.png}
  \caption{Ilustração da arquitetura em pilha do Apache Spark}
  {\bf Fonte:} \cite{LearningSpark}
  \label{fig:sparkStack}
\end{figure}

\subsection{Módulos do Apache Spark}

O Spark Core é o principal módulo do Apache Spark, responsável principalmente pelo gerenciamento de memória,  tasks (conceito explicado em \ref{taskSection}) e tolerância a falha. Ainda nele, a abstração conhecida como  RDD é definida, cujo papel é o de representar uma coleção de dados distribuídos e manipulados em paralelo. Os RDDs em Java são representados pela classe JavaRDD, criados através da classe JavaSparkContext (contexto da aplicação), que é instanciada recebendo como parâmetro um objeto SparkConf, contendo informações relacionadas ao nome da aplicação e o endereço em que ela será executada, pondendo ser local, ou, em cluster.

Outro módulo é o Spark Streaming, o qual realiza o processamento de dados em stream. Os streams são representados por uma sequência de RDDs, conhecida como DStream. O contexto de um streaming (JavaStreamingContext) é criado usando as configurações da aplicação e o intervalo no qual cada DStream será definido. Após isso, tais streams são atribuídos a um objeto da classe JavaReceiverInputDStream.

Além dos módulos detalhados nos parágrafos anteriores, é relevante mencionar o (i) Spark SQL, responsável por trabalhar com dados estruturados; o (ii) MLib, relacionado ao aprendizado de máquina, contendo algorítimos tais como o de classificação, regressão, "clusterização", filtragem colaborativa, avaliação de modelo e importação de dados; e o (ii) GraphX, que é composto por uma biblioteca para manipulação de grafos e computações paralelas. Por fim, o Spark também possui um administrador de cluster padrão, conhecido como Standalone Scheduler \cite{Spark}, tendo também suporte ao YARN e Apache Mesos.

\subsection{Composição Interna do Apache Spark}
\label{sparkInternalsSection}

Nesta seção é explicada a composição interna do Apache Spark, expondo os componentes que permitem a execução distribuída de uma aplicação spark, tais como o Driver Program, Spark Context, Worker Node e Executor.
Também são explicados os conceitos sobre as operações de Transformação e Ação, e os relativos a Job, Stage, Task e Partição RDD.

\subsubsection{Modelo de execução das aplicações Spark}
\label{sparkModelSection}

O modelo de execução das aplicações Spark é definido pela relação composta por um driver, SparkContext, executors e tasks, conforme ilustrado na Fig. \ref{fig:sparkComponents}. Nessa interação, as aplicações Spark funcionam num Worker Node (qualquer nó capaz de de executar código de aplicação localmente ou num cluster) como uma espécie de Driver, o qual executa operações paralelas e define dados distribuídos sobre um cluster. Além disso, o driver é responsável por encapsular a função principal da aplicação e prover acesso ao Spark, utilizando o objeto da classe SparkContext. Tal objeto é usado também para representar uma conexão com um cluster e construir RDDs \cite{LearningSpark}. 

Após a construção de um RDD, é possível executar operações sobre ele. Essas operações são realizadas por executors, processos administrados por uma aplicação Spark (cada aplicação tem os seus próprios executors); nos quais há espaços reservados para execução de tasks (conceito explicado na seção \ref{taskSection}). Há dois tipos de operações: (i) Ações (actions) e (ii) Transformações (transformations) \cite{Spark}. O primeiro tipo retorna um resultado ao driver após computações sobre um conjunto de dados de acordo com uma função. Sendo o segundo, responsável por gerar novos conjuntos de dados (RDDs) através, também, de funções especificadas \cite{LearningSpark}. 

\begin{figure}[htb]
  \centering
    \includegraphics[width=0.5\textwidth]{Imagens/sparkComponentsImage.png}
  \caption{Componentes do Spark para execução distribuída}
  {\bf Fonte:} \cite{LearningSpark}
  \label{fig:sparkComponents}
\end{figure}

\subsubsection{Job}
\label{jobSection}

A abstração do conceito de  job está relacionada com o de action. Mais especificamente, um job é o conjunto de estágios (stages) resultantes de uma
determinada  action. Por exemplo, quando o método count() é invocado (para realizar a contagem de elementos dentro de um RDD), cria­-se um job composto por um ou mais estágios. Os jobs, por padrão, são escalonados para serem executados em ordem \abrv[FIFO -- First In, First Out]{FIFO (First In, First Out)}. Além disso, o scheduler do Spark é responsável por criar um plano de execução física, o qual é utilizado para calcular as RDDs necessárias para executar a ação invocada \cite{LearningSpark}, \cite{SparkInternals}.

Em tal plano de execução física, defini­-se basicamente um grafo acíclico dirigido (DAG), relacionando as dependências existentes entre os RDDs, numa espécie de linhagem de execução (lineage). Após isso, a partir da última RDD do último estágio, cada dependência é calculada, de trás para frente, para que posteriormente os RDDs dependentes possam ser calculados, até que todas as actions necessárias tenham terminado \cite{LearningSpark}, \cite{SparkInternals}.

\subsubsection{Stage}
\label{stageSection}

A divisão de um job resulta no conceito de stage, ou seja, jobs são compostos por um ou mais stages, os quais têm  tasks a serem executadas. Nem sempre a relação entre  stages e RDDs será de 1:1. No mais simples dos casos, para cada RDD há um stage, sendo possível nos mais complexos haver mais de um stage gerado por um único RDD \cite{LearningSpark}, \cite{SparkInternals}.

Por exemplo, havendo três RDDs no grafo RDD, não necessariamente haverão três stages. Um dos motivos para isso acontecer é quando ocorre pipelining, situação na qual é possível reduzir o número de  stages, calculando os valores de alguns  RDDs  utilizando unicamente informac?o?es de seus antecessores, sem movimentação de dados de outros RDDs \cite{LearningSpark}, \cite{SparkInternals}.

Além da possibilidade do número de stages ser reduzido, o contrário acontece quando fronteiras entre  stages são definidas. Tal situação ocorre porque algumas transformações, como a reduceByKey (função de agregação por chaves), podem resultar em reparticionamento do conjunto de dados para a computação de alguma saída, exigindo dados de outros RDDs para a formação de um único RDD. Assim, em cada fronteira entre os  stages, tasks do estágio antecessor são responsáveis por escrever dados para o disco e buscar tasks no estágio sucessor, através da rede, resultando em um processo custoso, conhecido como shuffling \cite{LearningSpark}, \cite{SparkInternals}.

O número de partições entre o estágio predecessor e sucessor podem ser diferentes, sendo possível customizá-lo, embora isso não seja recomendável. Tal aconselhamento é devido ao fato de que se o número for modificado para uma pequena quantidade de partições, tais podem sofrer com tasks overloaded (sobrecarregadas), do contrário, havendo partições em excesso, resultará em um alto número de shuffling entre elas \cite{LearningSpark}, \cite{SparkInternals}.

Em resumo, shuffling sempre acontecerá quando for necessário obter dados de outras partições para computar um resultado, sendo esse um procedimento custoso devido ao número de operações de entrada e saída envolvendo: leitura/escrita em disco e transferência de dados através da rede. No entanto, se necessário, o Spark provê uma forma eficiente para reparticionamento, conhecida como coalesce(), a qual reduz o número de partições sem causar movimentação de dados \cite{LearningSpark}.

\subsubsection{Task}
\label{taskSection}

A abstração do conceito task  está relacionada principalmente com stage, pois, uma vez que os estágios são definidos, tasks são criadas e enviadas para um scheduler interno. Além disso, tasks estão muito próximas da definição de partition, pelo fato de ser necessária a existe?ncia de uma task para cada partition, para executar as computações necessárias sobre ela \cite{LearningSpark}.

Portanto, o número de tasks em um stage é definido pelo número de partições existentes no RDD antecessor. E, por outro lado, o número de partições em um determinado RDD é igual ao número de partições existentes no RDD do qual ele depende. No entanto, há exceções em caso de (i) coalescing, processo o qual permite criar um RDD com menos partições que seu antecessor; (ii) união, sendo o número de partições resultado da soma do número de partições predecessoras; (iii) produto cartesiano, produto dos predecessores \cite{LearningSpark}.

Cada  task internamente é divida em algumas etapas, sendo elas: (i) carregamento dos dados de entrada, sejam eles provenientes de unidades de armazenamento (caso o RDD seja um RDD de entrada de dados), de um RDD existente (armazenado em memória cache), ou, de saídas de outro RDD (processo de shuffling), (ii) processamento da operação necessária para computação do RDD representado por ela, (iii) escrever a saída para o processo de shuffling, para um armazenamento externo ou para o driver (caso seja o RDD final de uma ação). Em resumo, uma  task é responsável por coletar os dados de entrada, processá-­los e, por fim, gerar uma saída \cite{LearningSpark}.

\section{Apache Storm}
\label{stormSection}

Apache Storm \cite{Storm} é uma plataforma de computação em cluster, com suporte a processamento de stream  de dados em tempo real. O Storm requer pouca manutenção, é de fácil de administração e tem suporte a qualquer linguagem de programação (que leia e escreva fluxos de dados padronizados), posto que em seu núcleo é utilizado o Apache Thrift \cite{Thrift} (framework que permite o desenvolvimento de serviços multilinguagem) para definir e submeter topologias (conceito definido em \ref{topologySection}) \cite{Storm}.

A arquitetura do Storm, conforme a Fig. \ref{fig:stormComponents}, é composta pelos seguintes componentes, a serem explicados posteriormente: Nimbus, ZooKeeper e Supervisor Node.

\begin{figure}[htb]
  \centering
    \includegraphics[width=0.5\textwidth]{Imagens/stormComponentsImage.png}
  \caption{Ilustração da arquitetura do Apache Storm}
  {\bf Fonte:} \cite{LearningStorm}
  \label{fig:stormComponents}
\end{figure}

\subsection{Composição interna do Apache Storm}

Nesta seção é explicada a composição interna do Apache Storm, expondo os principais componentes que permitem a execução distribuída de uma topologia Storm, tais como o Nimbus, ZooKeeper e Supervisor nodes.

\subsubsection{Nimbus}
\label{nimbusSection}

Nimbus é o processo master executado num cluster Storm, tendo ele uma única instância e sendo responsável por distribuir o código da aplicação (job) para os nós workers (computadores que compõem o cluster), aos quais são atribuídas tasks (parte de um job). As tasks são monitoradas pelo Supervisor node, sendo reiniciadas em caso de falha e quando requisitado. Ainda, caso um Supervisor node falhe continuadamente, o job é atribuído para outro nó worker \cite{LearningStorm}, \cite{StormPython}. 

O Nimbus utiliza um protocolo de comunicação sem estado (Stateless protocol), ou seja, cada requisição é tratada individualmente, sem relação com a anterior, não armazenando dados ou estado \cite{Techopedia}, sendo assim todos os seus dados são armazenados no ZooKeeper (definido em \ref{zookeeperSection}). Além disso ele é projetado para ser fail­-fast, ou seja, em caso de falha é rapidamente reiniciado, sem afetar as  tasks em execução nos nós  workers \cite{LearningStorm}, \cite{StormPython}.

\subsubsection{Supervisor node}
\label{supervisorSection}

Cada Supervisor node é responsável pela administração de um determinado nó do cluster Storm; gerenciando o ciclo de vida de processos workers relacionados a execução das tasks (partes de uma topologia) atribuídas a ele próprio. Os workers quando em execução emitem "sinais de vida" (heartbeats), possibilitando o supervisor detectar e reiniciar caso não estejam respondendo. E, assim como o Nimbus, um Supervisor node é projetado para ser  fail­-fast \cite{LearningStorm}, \cite{StormPython}.

\subsubsection{ZooKeeper}
\label{zookeeperSection}

O ZooKeeper Cluster \cite{ZooKeeper} é responsável por coordenar processos, informações compartilhadas, tasks submetidas ao Storm e estados associados ao cluster, num contexto distribuído e de forma confiável, sendo possível aumentar o nível de confiabilidade tendo mais de um servidor ZooKeeper. O ZooKeeper atua também como o intermediário da comunicação entre Nimbus e os Supervisor nodes, pois eles não se comunicam diretamente entre si, ambos também podem ser finalizados sem afetar o cluster, visto que todos os seus dados, são armazenados no ZooKeeper, como já mencionado anteriormente \cite{LearningStorm}, \cite{StormPython}.

\subsubsection{Topologia}
\label{topologySection}

A topologia Storm, ilustrada na Fig. \ref{fig:stormTopology}, é uma abstração que define um grafo acíclico dirigido (DAG), utilizado para computações de streams. Cada nó desse grafo é responsável por executar algum processamento, enviando seu resultado para o próximo nó do fluxo. Após definida a topologia, ela pode ser executada localmente ou submetida a um cluster \cite{LearningStorm}, \cite{StormPython}.

Stream é um dos componentes da topologia Storm, definido como uma sequência de tuplas independentes e imutáveis, fornecidas por um ou mais spout e processadas por um ou mais bolt. Cada stream tem o seu respectivo ID, que é utilizado pelos bolts para consumirem e produzirem as tuplas. As tuplas compõem uma unidade básica de dados, suportando os tipos de dados (serializáveis) no qual a topologia está sendo desenvolvida.

\begin{figure}[htb]
  \centering
    \includegraphics[width=0.5\textwidth]{Imagens/stormTopologyImage.png}
  \caption{Ilustração de uma topologia do Storm}
  {\bf Fonte:} \cite{LearningStorm}
  \label{fig:stormTopology}
\end{figure}

\paragraph{Bolt.} Os bolts são unidades de processamento de dados (streams), sendo eles responsáveis por executar transformações simples sobre as tuplas, as quais são combinadas com outras formando complexas transformações. Também, eles podem ser inscritos para receberem informações tanto de outros bolts, quanto dos spouts, além de produzirem streams como saída \cite{LearningStorm}.

Tais streams são declarados, emitidos para outro bolt e processados, respectivamente, pelos métodos declareStream, emit e execute. As tuplas não precisam ser processadas imediatamente quando chegam a um bolt, pois, talvez haja a necessidade de aguardar para executar alguma operação de junção (join) com outra tupla, por exemplo. Também, inúmeros métodos definidos pela interface Tuple podem recuperar meta­dados associados com a tupla recebida via execute \cite{LearningStorm}.

Por exemplo, se um ID de mensagem está associado com uma tupla, o método execute deverá publicar um evento ack, ou, fail, para o bolt, caso contrário o Storm não tem como saber se uma tupla foi processada. Sendo assim, o bolt envia automaticamente uma mensagem de confirmação após o término da execução do método execute e, em caso de um evento de falha, é lançada uma exceção \cite{LearningStorm}.

Além disso, num contexto distribuído, a topologia pode ser serializada e submetida, via Nimbus, para um cluster. No qual, será processada por worker nodes. Nesse contexto, o método prepare pode ser utilizado para assegurar que o bolt está, após a desserialização, configurado corretamente para executar as tuplas \cite{LearningStorm}, \cite{StormPython}.

\paragraph{Spout.} Na topologia Storm um  Spout é o responsável pelo fornecimento de tuplas, as quais são lidas e escritas por ele utilizando uma fonte externa de dados \cite{LearningStorm}. 

As tuplas emitidas por um  spout são rastreadas pelo Storm até terminarem o processamento, sendo emitida uma confirmação ao término dele. Tal procedimento somente ocorre se um ID de mensagem foi gerado na emissão da tupla e, caso esse ID tenha sido definido como nulo, o rastreamento não irá acontecer \cite{LearningStorm}.

Outra opção é definir um  time­out a topologia, sendo dessa forma enviada uma mensagem de falha para o  spout,  caso a tupla não seja processada dentro do tempo estipulado. Sendo necessário, novamente, definir um ID de mensagem. O custo dessa confirmação do processamento ter sido executado com sucesso é a pequena perda de performance, que pode ser relevante em determinados contextos; sendo assim é possível ignorar a emissão de IDs de mensagens
\cite{LearningStorm}.

Os principais métodos de um spout são: o open(), executado quando o spout é inicializado, sendo nele definida a lógica para acesso a dados de fontes externas; o de declaração de stream (declareStream) e o de processamento de próxima tupla (nextTuple), que ocorre se houver confirmação de sucesso da tupla anterior (ack), sendo o método fail chamado pelo Storm caso isso não ocorra \cite{LearningStorm}.

Por fim, nenhum dos métodos utilizados para a construção de um  spout devem ser bloqueante, pois o Storm executa todos os métodos numa mesma  thread. Além disso, todo  spout tem um buffer interno para o rastreamento dos status das tuplas emitidas, as quais são mantidas nele até uma confirmação de processamento concluído com sucesso (ack) ou falha (fail); não sendo inseridas novas tuplas (via nextTuple) no buffer quando ele esá cheio \cite{LearningStorm}.
