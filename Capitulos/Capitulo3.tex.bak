% Capítulo 3
\chapter{Aplicações desenvolvidas e revisão da literatura}
\label{chapter3}

Nesse capítulo, a seção \ref{apps} aborda as questões relacionadas as aplicações desenvolvidas. Em seguida, na seção \ref{literatureReview}, é realizada uma breve revisão da literatura sobre alguns requisitos importantes, relacionados as ferramentas ESPs escolhidas anteriormente. 

\section{Aplicações desenvolvidas}
\label{apps}

Após a escolha das plataformas para processamento de eventos em tempo real, quatro aplicações foram desenvolvidas. A explicada na subseção \ref{webApp}, exibe numa aplicação web um mapa contendo informações sobre as métricas de e-Participação e uma visão da polaridade dos sentimentos contidos nos tweets processados. A subseção \ref{batchApp}, refere-se à aplicação responsável por coletar os tweets e processar as métricas de e-Participação; a da subseção \ref{sparkApp}, por sua vez, usa o Spark Streaming para realizar análise de polaridade dos streams de tweets; e a referente a subseção \ref{stormApp}, realiza o mesmo procedimento, mas com o Storm. 

\sloppy
\subsection{Aplicação web para visualização das métricas relacionadas a e-Participação}
\label{webApp}

A aplicação web foi desenvolvida utilizando o framework web Django \cite{Django}, unicamente devido a sua simplicidade. Nela, há somente uma página construída usando HTML, JavaScript e \abrv[CSS -- Cascading Style Sheets]{CSS (Cascading Style Sheets)}, na qual o mapa para a visualização das métricas e polaridades é exibido. O mapa, por sua vez, é obtido com o suporte da API MapsJavaScript \cite{GoogleDevelopers} sendo nele sobrepostas camadas do Google Fusion Tables (aplicação web experimental para visualização de dados, coleta e compartilhamento de tabelas \cite{FusionTables}).

As métricas e polaridades podem ser escolhidas através de uma caixa de seleção (ComboBox), sendo assim, para cada Estado, se sua respectiva média for maior que a nacional a região dele no mapa é sobreposta com uma camada azul, se menor, vermelha. Ainda, clicando num Estado é possível visualizar um painel informativo com os valores das médias, medianas, mínimo, máximo, variância e desvio padrão, assim como a quantidade de tweets, seguidores, e o tempo de existência da conta.

Além disso, há conexão via API com a aplicação responsável por realizar a coleta de \textit{tweets} e processamento das métricas. O tempo necessário para o levantamento de todas essas informações é em torno de 1h30m, devido aos limites de requisições à API do Twitter, explicado na subseção \ref{batchApp}, e do Fusion Tables, limitado em 30 chamadas por minuto \cite{GoogleDevelopers} (ou seja, a cada 30 chamadas a aplicação aguarda um intervalo de 1 minuto para realizar mais 30 requisições). Devido a isso, essa opção somente é habilitada no código quando necessário. 

O código dessa aplicação está disponível no repositório localizado em \cite{GitRepository}, sendo "brazilian\_smart\_cities\_map" o nome do projeto.

\sloppy
\subsection{Aplicação para processamento de tweets e coleta de métricas relacionadas a e-Participação}
\label{batchApp}

O primeiro passo no desenvolvimento dessa aplicação, foi decidir as contas (perfis) das quais os \textit{tweets} seriam processados. Como, normalmente, as capitais dos estados têm maior concentração de pessoas, optou-se por fazer um levantamento dos perfis oficiais de suas respectivas prefeituras, para então posteriormente realizar o processamento dos \textit{tweets}. Sendo assim, a Tab. \ref{tab:tweetAccounts} lista as contas relacionadas as prefeituras municipais das capitais dos vinte e sete estados brasileiros.

Em seguida, foram escolhidas quais métricas dessas contas seriam possíveis e importantes de coletar, tendo como referência \cite{AVisionOfSocialMedia}. Sendo assim, selecionou-se os seguintes indicadores respectivos ao Twitter: média do número de \textit{tweets}, seguidores, \textit{retweets} (compartilhamento de um determinado \textit{tweet}), comentários realizados por usuários, réplicas a \textit{tweets} e tempo de resposta. As métricas referentes ao número de usuários acompanhando as listas (junções de \textit{timelines}) dos perfis e o total delas existentes foram desconsideras, pois são relacionadas a contas diferentes das em questão.

De acordo com \cite{AVisionOfSocialMedia}, através dessas métricas é possível obter indicadores relacionados a e-Participação. Alguns dos indicadores propostos  pela \abrv[SNR -- Social Network Ratio]{SNR (\textit{Social Network Ratio})} para Redes Sociais são: Atividade, ou, audiência estimada; Tamanho, ou, esforço realizado pelo perfil para se comunicar; Visibilidade, ou, número total de menções ao perfil; Interação, ou, capacidade de impacto (viralização) da comunicação \cite{AVisionOfSocialMedia}.

Portando, pode-se mapear a métrica número de seguidores ao indicador Atividade; a média de menções realizadas para o de Visibilidade; o número de \textit{tweets}, réplicas por dia e médias relacionadas ao tempo de resposta ao indicador Tamanho; e por último, as médias de \textit{retweets} e favoritos ao de Interação. A Fig. \ref{fig:twitterDataAnalysisClassDiagram} exibe o diagrama de classes da aplicação desenvolvida para o processamento de \textit{tweets} e coleta dessas métricas.

\begin{figure}[!htb]
  \centering
    \captionsetup{justification=centering}
    \includegraphics[width=1.2\textwidth, angle=90]{Imagens/twitterDataAnalysisClassDiagram.png}
  \caption{Diagrama de classes da aplicação desenvolvida para processamento e coleta de métricas relacionadas a e-Participação}
	{\bf Fonte:} Elaboração própria
  \label{fig:twitterDataAnalysisClassDiagram}
\end{figure}

A aplicação exibida no diagrama de classes da Fig. \ref{fig:twitterDataAnalysisClassDiagram} foi desenvolvida na linguagem de programação Java, devido a sua praticidade de uso, utilizando o framework para Web Services, Apache CXF \cite{ApacheCXF}, para expor três de seus serviços através de uma REST API. O primeiro deles é exposto pela interface ITweetService, o segundo pela ISparkService, e o terceiro via ISentiments, pelos seguintes \textit{endpoints}, respectivamente: "$\backslash$tweets", "$\backslash$metrics" e "$\backslash$sentiments", permitindo integrá-la a aplicação web descrita na subseção \ref{webApp}. 

A classe que implementa a interface ITweetService, é responsável por realizar a coleta dos 3.200 \textit{tweets} mais recentes (se disponíveis) de cada conta, através do \textit{endpoint} "statuses/user\_timeline". Tal quantidade é limitada pela API do Twitter, a qual pode ser alcançada por no máximo 180 requisições, num intervalo de 15 minutos, com autenticação via conta de usuário \cite{TwitterDevelopers}.

Outro endpoint utilizado foi "search/tweets", para pesquisar as menções realizadas pelos cidadãos as contas das prefeituras. O limite de coleta é de 100 tweets para cada requisição, sendo possível realizar 180 a cada 15 minutos. Os endpoints da API do Twitter foram acessados com o suporte da biblioteca Twitter4J \cite{Twitter4J}.

Durante a coleta dos \textit{tweets}, eles são mapeados para as seguintes classes do modelo da aplicação: UserInfo, que contém as informações respectivas ao usuário da conta (número de seguidores, \textit{tweets}, localização, \textit{username} e data de criação da conta), e TweetInfo, contendo as relacionadas ao \textit{tweet} (data de criação, \textit{id} do \textit{tweet} de réplica e a qual usuário ele se refere, quantidade de \textit{retweets}, favoritos, se é menção ou não, e o tempo de resposta calculado). Em seguida, os modelos são persistidos via a interface ITweetsDAO, a qual se comunica com o banco de dados não relacional MongoDB \cite{Mongo}.

Os \textit{tweets} coletados por essa aplicação são os mais recentes e anteriores a data 18/06/2016 (incluindo-a). Como essa coleta não foi realizada sob um \textit{stream} de \textit{tweets}, a interface ISparkService expõe o serviço responsável por realizar o processamento em \textit{batch} desses \textit{tweets}, coletando as métricas relacionadas a e-Participação. Sendo assim, cada métrica é recuperada do banco de dados e mapeadas para um RDD de \textit{doubles}, quando números, ou, de \textit{strings}, no caso da data.

\begin{figure}[!htb]
  \centering
  \captionsetup{justification=centering}
    \includegraphics[width=0.6\textwidth]{Imagens/sparkDiagramMapToDouble.png}
  \caption{Diagrama do mapeamento entre um Resilient Distributed Dataset de Long para Double}
	{\bf Fonte:} Elaboração própria
  \label{fig:sparkDiagramMapToDoble}
\end{figure}

Sendo assim, após recuperar as métricas, é possível mapeá-las para um RDD de \textit{doubles}, por meio do qual são obtidos os valores relacionados as suas respectivas médias, medianas, variâncias, máximos, mínimos e desvios padrões. As informações sobre datas, como \textit{strings}, são mapeadas para o valor 1, representando a ocorrência de um \textit{tweet} nesse dia; compondo uma sequência de pares, que permite obter e mapear as quantidades de \textit{tweets} por dia a um RDD de \textit{doubles}. Tais processos de mapeamentos são ilustrados nas Fig. \ref{fig:sparkDiagramMapToDoble} e Fig. \ref{fig:sparkDiagramMapDateToDouble}.

Por fim, a interface IFusionTable é utilizada para submeter os valores das métricas relacionadas a e-Participação a uma Fusion Table \cite{eParticipationMetrics}, via a API do Google Fusion Tables, ocorrendo o mesmo para as referentes as polaridades de sentimentos, processados pelas aplicações explicadas em \ref{sparkApp} e \ref{stormApp}. Os valores dessa tabela são utilizados para criar o mapa contido na aplicação web.

\begin{figure}[!htb]
  \centering
  \captionsetup{justification=centering}
    \includegraphics[width=0.7\textwidth]{Imagens/sparkDiagramMapDateToDouble.png}
  \caption {Diagrama do mapeamento entre um Resilient Distributed Dataset de Datas para suas respectivas frequências em Double}
	{\bf Fonte:} Elaboração própria
  \label{fig:sparkDiagramMapDateToDouble}
\end{figure}

O código dessa aplicação está disponível no repositório localizado em \cite{GitRepository}, sendo "twitter-data-analysis" o nome do projeto.

\begin{table}[!htb]	
	\center
		% Título de tabelas sempre aparecem antes da tabela
	\caption{Contas do Twitter relacionadas as prefeituras municipais das capitais dos vinte e sete estados brasileiros e quantidade de tweets processados para coleta das métricas relacionadas a e-Participação}
	\bigskip
	\label{tab:tweetAccounts}
	{
		\begin{tabular}{c|c|c|c}
			\hline
            {\bf Estado} & {\bf Capital} & {\bf Conta no Twitter} & {\bf Tweets processados}\\
			\hline
			Acre & Rio Branco & PrefRioBranco & 3265\\
			Alagoas & Maceió & PrefMaceio & 3308\\
			Amapá & Macapá & PMMacapa & 3618\\
			Amazonas & Manaus & PrefManaus & 3230\\
			Bahia & Salvador & agecomsalvador & 1231\\			
			Distrito Federal & Brasília & Gov\_DF & 3559\\
			Ceará & Fortaleza & prefeiturapmf & 3678\\
			Espírito Santo & Vitória & VitoriaOnLine & 3249\\
			Goiás & Goiânia & PrefeituraGy & 4053\\
			Maranhão & São Luís & PrefeituraSL & 3720\\
			Mato Grosso & Cuiabá & prefeitura\_CBA & 3211\\
			Mato Grosso do Sul & Campo Grande & cgnoticias & 3200\\
			Minas Gerais & Belo Horizonte & prefeiturabh & 3623\\
			Paraná & Curitiba & Curitiba\_PMC & 4951\\
			Paraíba & João Pessoa & pmjponline & 3677\\
			Pará & Belém & prefeiturabelem & 1131\\
			Pernambuco & Recife & prefrecife & 3725\\
			Piauí & Teresina & prefeitura\_the & 3392\\
			Rio Grande do Norte & Natal & NatalPrefeitura & 3360\\
			Rio Grande do Sul & Porto Alegre & Prefeitura\_POA & 3529\\
			Rio de Janeiro & Rio de Janeiro & Prefeitura\_Rio & 6387\\
			Rondônia & Porto Velho & prefeitura\_pvh & 2805\\
			Roraima & Boa Vista & PrefeituraBV & 3201\\
			Santa Catarina & Florianópolis & scflorianopolis & 3448\\
			Sergipe & Aracaju & PrefeituraAracaju & 3423\\
			São Paulo & São Paulo & prefsp & 4330\\
			Tocantins & Palmas & cidadepalmasy & 3574\\
			\hline	
              {\bf Total} & { } & { } & 93878\\			
			\hline			 
		\end{tabular}
	}
		\center {\bf Fonte:} Elaboração própria
\end{table}

\bigskip
\bigskip
\bigskip
\bigskip

\subsection{Aplicação para processamento de stream de tweets, utilizando Spark Streaming}
\label{sparkApp}

A aplicação que utiliza o Spark Streaming, foi desenvolvida na linguagem de programação Java. No início de sua execução, é criado um contexto de \textit{stream} no qual é definindo o \textit{cluster} onde ela será executada e o intervalo de criação de cada RDD. Tais Resilient Distributed Datasets, são compostos ordenadamente em sequência, formando a abstração conhecida como DStream. No nosso caso, cada RDD é criado após 30000ms; sendo compostos pelos \textit{tweets} coletados filtrando os nomes das contas das prefeituras no Twitter, enumerados na classe KeyWords, ilustrada no diagrama da Fig. \ref{fig:sparkDataAnalysisClassDiagram}.

O processo mencionado anteriormente, executado pela classe SparkStreaming, começa após a inicialização do contexto de stream, sendo os \textit{tweets} coletados pela classe TwitterUtils (do próprio Spark Streaming). Durante a coleta dos \textit{streams} de \textit{tweets} (eventos), cada RDD é mapeado para a classe TweetInfo (do modelo da aplicação), através de uma transformação map. Na sequência, as ações forEachRDD e collect são executadas para inserir os \textit{tweets} processados no banco de dados não relacional MongoDB, conforme ilustrado na Fig. \ref{fig:sparkDataAnalysisDiagram}.

\begin{figure}[!htb]
  \centering
  \captionsetup{justification=centering}
    \includegraphics[width=0.8\textwidth]{Imagens/sparkDataAnalysisDiagram.png}
  \caption{Fluxo do processamento de dados da aplicação utilizando o Spark Streaming}
	{\bf Fonte:} Elaboração própria
  \label{fig:sparkDataAnalysisDiagram}
\end{figure}

A análise das polaridades dos sentimentos do conteúdo contido nos \textit{tweets} ocorre durante a última parte do mapeamento, sendo antes disso realizados alguns processamentos para facilitar e viabilizar esse procedimento. Portanto, primeiramente, os textos contidos nos \textit{tweets} são extraídos e formatados para minúsculo. Em seguida, todas as menções são identificadas pelo padrão em que ocorrem no Twitter (@\textit{displayname}, nome exibido para os demais usuários da Rede Social) e removidas, assim como as referências a endereços de sites.

No Twitter, quando um \textit{tweet} é compartilhado ele é marcado com a notação "RT", abreviação de \textit{retweet}, a qual também é removida do texto em processamento. Além disso, alguns símbolos são removidos, tais como: ., ., \!, \%, \#, etc. Sendo esse o conjunto de processamentos realizados para "limpar" inicialmente o texto, após o qual se inicia o Processamento de Linguagem Natural.

Com esse propósito, usou-se a biblioteca OpenNLP \cite{OpenNlp} para a tokenização dos \textit{tweets}. Após a obtenção dos \textit{tokens}, outros processamentos foram necessários para melhorar o desempenho da fase seguinte, como a substituição das palavras normalmente abreviadas (vc - você, msm - mesmo, pq - porque, q - que, n - não, etc) e de expressões (sqn - só que não, kkk, hahaha, rsrsrs, para situações comumente engraçadas) para seus respectivos formatos formais, utilizando dicionários previamente construídos. Além disso, foram removidos os \textit{tokens} contendo "\textit{stopwords}" (palavras vazias), termo utilizado para as palavras comuns de um certo idioma \cite{DataMining}.

Após a obtenção dos \textit{tokens}, foram atribuídas a eles \textit{tags} referentes as suas respectivas classes gramaticais, e, por fim, associadas a uma \textit{part-of-speech} para cada \textit{tweet}, usando os \textit{tokens} e \textit{tags} obtidas, finalizando a parte do Processamento de Linguagem Natural. Seguindo então, para a última etapa, que é a da análise de polaridade dos sentimentos, tendo como base para isso os adjetivos presentes em cada \textit{tweet}.

A análise das polaridades dos sentimentos foi realizada com o suporte do Sentilex (versão 1), que é um léxico de sentimentos para o Português, constituído de 6.321 lemas adjetivais (por convenção, na forma masculina singular) e 25.406 formas flexionadas, contendo como um de seus atributos a polaridade do adjetivo. As polaridades são classificadas em positivo (67\% de precisão), negativo (82\% de precisão), ou, neutro (45\% de precisão), possibilitando estimar o sentimento expresso por um determinado texto \cite{Sentilex}.

Os sentimentos são estimados contabilizando as polaridades presentes em cada \textit{tweet} e o sentimento expresso pelos \textit{emotions} (se houver), assim sendo, por exemplo, o emotion "(:" incrementa 1 para a polaridade positiva, e 1 para a negativa caso seja ":(". Também, considera-se a presença de advérbios de negação, os quais modificam o significado do verbo, adjetivo e de outros advérbios \cite{Priberam}, alterando consequentemente a polaridade. Por fim, é realizada uma simples normatização com os somatórios das polaridades positivas e negativas, seguindo o seguinte modelo:
{\begin{center} score = ($\Sigma$ positivo - $\Sigma$ negativo) $\div$  ($\Sigma$ positivo + $\Sigma$ negativo)\end{center}}

Caso o \textit{score} seja menor do que zero, o \textit{tweet} é classificado com polaridade negativa, se o seu complemento for maior do que 0.5, tem-se polaridade positiva e se igual a zero, neutra. Sendo assim, as informações sobre a polaridade (sentimento) do \textit{tweet}, seu id e suas respectivas menções (recuperadas do \textit{tweet} original) são armazenadas no banco de dados não relacional MongoDB. As polaridades são exibidas no mapa da aplicação web.

O código dessa aplicação está disponível no repositório localizado em \cite{GitRepository}, sendo "spark-data-analysis" o nome do projeto, e seu respectivo diagrama de classe é ilustrado na Fig. \ref{fig:sparkDataAnalysisClassDiagram}

\bigskip
\bigskip
\bigskip

\begin{figure}[!htb]
  \centering
  \captionsetup{justification=centering}
    \includegraphics[width=0.8\textwidth]{Imagens/sparkDataAnalysisClassDiagram.png}
  \caption{Diagrama de classes da aplicação utilizando o Spark Streaming}
	{\bf Fonte:} Elaboração própria
  \label{fig:sparkDataAnalysisClassDiagram}
\end{figure}

\subsection{Aplicação para processamento de stream de tweets, utilizando Storm}
\label{stormApp}

A aplicação que utiliza o Storm para o processamento de \textit{stream} de \textit{tweets}, foi desenvolvida utilizando a linguagem de programação Java. Nela é construída uma topologia, ilustrada na Fig. \ref{fig:stormTopologyApp}, composta por um \textit{Spout} (classe Twitter), responsável pela conexão ao Twitter e coleta dos \textit{tweets}, tendo como filtro o nome das contas das prefeituras no Twitter, utilizando a biblioteca Twitter4J.

\begin{figure}[!htb]
  \centering
  \captionsetup{justification=centering}
    \includegraphics[width=0.8\textwidth]{Imagens/stormTopologyApp.png}
  \caption{Topologia da aplicação utilizando Storm}
	{\bf Fonte:} Elaboração própria
  \label{fig:stormTopologyApp}
\end{figure}

Em sequência, há seis \textit{bolts}, responsáveis pelo processamento (o mesmo realizado pela aplicação Spark) dos \textit{tweets} coletados. O primeiro deles, classe TweetCleanerBolt, ilustrada na Fig. \ref{fig:stormApplicationClassDiagram}, remove as menções e \textit{urls} contidas no \textit{tweet}, após isso os símbolos existentes são removidos pelo \textit{bolt} Symbols Cleaner.

Continuando, a parte do Processamento de Linguagem Natural é realizado pelos \textit{bolts} Tokenizer e Tag. Na finalização do processo, o \textit{bolt} SentimentAnalyser calcula a polarização de cada \textit{tweet}, emitindo-os para o \textit{bolt} Persisting, responsável pelo armazená-los no banco de dados não relacional MongoDB. Vale ainda mencionar, que os resultados de cada bolt são "setados" na classe TweetStream, do modelo da aplicação, o que foi necessário devido ao fato de nem todos os tipos de dados serem serializáveis, como o caso do UserMentionEntity, da biblioteca Twitter4J.

O código dessa aplicação está disponível no repositório localizado em \cite{GitRepository}, sendo "storm-data-analysis" o nome do projeto

\begin{figure}[!htb]
  \centering
  \captionsetup{justification=centering}
    \includegraphics[width=1\textwidth]{Imagens/stormApplicationClassDiagram.png}
  \caption{Diagrama de classes da aplicação utilizando o Storm}
	{\bf Fonte:} Elaboração própria
  \label{fig:stormApplicationClassDiagram}
\end{figure}

\section{Revisão da Literatura}
\label{literatureReview}

Nessa seção, é realizada uma breve revisão da literatura sobre o Apache Spark e Storm, objetivando compará-los sobre alguns requisitos, sendo a subseção \ref{rtp} sobre o requisito de Processamento de grande volume de dados em Tempo Real, a \ref{faultTolerance} a respeito de Tolerância a Falhas, a \ref{garantiesProcessing} sobre Garantias de processamento, a \ref{scalability} em relação a Escalabilidade e, por fim, a \ref{programmingModel} sobre o Modelo de Programação de ambas as ferramentas. 

\subsection{Processamento de Grande Volume de Dados em Tempo Real}
\label{rtp}

Quanto ao requisito de Processamento de Grandes Volumes de Dados em Tempo Real, de acordo com a referência \cite{NrtPresentation}, o Apache Spark pode processar até 670k de registros por segundo e por nó, enquanto que o Storm 155k. Portanto, ambas as ferramentas são capazes de processar grande fluxo de dados.

No entanto, elas se diferenciam no requisito de processamento em tempo real. O Spark tem latência de 0.5­2s \cite{DStream2}, e devido a esse delay de até alguns segundos, é considerado uma ferramenta de \textit{Near­ Real­ Time}. O Storm, por outro lado, tem como latência de 1­100ms \cite{DStream}, \cite{DStream2}, sendo por isso um sistema com processamento em \textit{Real Time}.

Como já mencionado na Fundamentação Teórica, quanto menor o valor de latência, mais rápido se obtém resposta a um dado evento. Além disso, no quesito de processamento em tempo real, também é importante avaliar o valor de throughput, o qual no Spark é maior em comparação ao do Storm \cite{DStream}, favorecendo menor tempo de processamento.

Como base no que foi dito anteriormente, nesse quesito o Spark é mais adequado as aplicações desenvolvidas, pois elas estão inseridas num contexto em que a propriedade de \textit{throughput} tem maior relevância. Isso, devido a quantidade de \textit{tweets} processados, tanto para análise das polaridades de sentimentos, com o módulo Spark Streaming, quanto para o processamento das métricas relacionadas a e-Participação. 

\subsection{Tolerância a Falhas}
\label{faultTolerance}

Discretized Streams (D­Streams) é um modelo de programação para processamento de \textit{streams} distribuídas, utilizado pelo Spark Streaming, capaz de fornecer Tolerância a Falhas, através do método \textit{parallel recovery} \cite{DStream3}. Nesse modelo, a tolerância a falhas é implementada através do conceito \textit{lineage}, o que permite as informações serem recuperadas paralelamente \cite{DStream4}.

O mecanismo de recuperação via \textit{lineage} é definido por um grafo acíclico dirigido (DAG), por meio do qual RDDs e D­Streams rastreiam, ao nível das partições RDDs, suas respectivas dependências e operações realizadas sob elas \cite{DStream4}. Sendo assim, os RDDs e D­Streams conseguem "saber" como foram construídos. Podendo, consequentemente, cada nó do \textit{cluster} reconstruí-­lo paralela e eficientemente em caso de falhas. Especificamente, o processo de recuperação é realizado computando novamente uma determinada partição RDD, re­executando as \textit{tasks} que a originaram \cite{DStream4}.

Visando prevenir infinitas re­-computações, também são realizados \textit{checkpoints} num determinado espaço de tempo, com replicações assíncronas de RDDs. Tal procedimento, não é necessário para todo o conjunto de dados, pois, como já mencionado, a recuperação executada por nós em paralelo é realizada com demasiada eficiência \cite{DStream4}. 

Todo o processo descrito até aqui é confiável quando a fonte dos dados pode ser lida novamente, no caso do Spark Streaming, é necessário haver alguma fonte externa para replicação dos dados \cite{Spark}. Além disso, se o \textit{Driver} for finalizado, devido ao fato dele manter o contexto da aplicação, todo o conteúdo em memória dos \textit{executors} é perdido \cite{Spark}.  

No Storm, a Tolerância a Falhas é aplicada a cada um de seus componentes. Por exemplo, se o \textit{worker} falha, ele é reinicializado pelo \textit{Supervisor} no próprio nó \cite{LearningStorm}. Caso o nó esteja indisponível, ou, falhando continuadamente, suas \textit{tasks} são então atribuídas a outro disponível no \textit{cluster}, via Nimbus \cite{StormPython}. 

O Nimbus e os \textit{supervisors}, armazenam seus estados no Zookeeper, podendo ser reinicializados sem perdê-los em caso de falha, se houver falha no Zookeeper, outra instância pode ser "eleita" para o lugar dele\cite{LearningStorm}. Caso algum \textit{supervisor} falhe, seus \textit{workers} são reatribuídos pelo Nimbus a outro \textit{supervisor}, no entanto, ficando impedido de receberem novas tuplas \cite{StormPython}.

Por sua vez, o Nimbus, dentre suas atribuições, é responsável também por reinicializar as \textit{tasks} caso uma delas falhe, e se o mesmo acontecer com ele próprio, as \textit{tasks} em execução não são afetadas, mas novas topologias são impedidas de serem submetidas ao \textit{cluster} \cite{LearningStorm}, assim como reatribuições \cite{StormPython}.

O modelo de recuperação de falhas do Spark pode ser uma boa escolha caso a aplicação permita perda de dados, em prol de eficiência \cite{DStream3}. Caso contrário, é necessário configurar uma fonte externa para replicação dos dados que estão sendo processados. Em contraste, a arquitetura do Storm, busca possibilitar que seus componentes falhem havendo pouco prejuízo para a aplicação, ainda assim a replicação pode adicionar mais uma camada de confiabilidade. 

Levando em consideração o exposto acima, a aplicação desenvolvida para o processamento de métricas, realiza-o em \textit{batch}, podendo ter acesso a fonte de dados para coletá-los novamente, em caso de falha. Além disso, a eficiência foi priorizada, não havendo prejuízo ao utilizar o Spark. Para aplicação que realiza análise de polaridade dos sentimentos, processando \textit{stream} de \textit{tweets}, é mais interessante o suporte a Tolerância a Falhas do Storm, principalmente devido longo tempo de execução dela.

\subsubsection{Garantia de processamento}
\label{garantiesProcessing}

Em adição a subseção anterior, o Spark Streaming e Storm possuem formas diferentes de garantir o processamento de um evento. No Spark Streaming há a garantia de que todo evento será processado exatamente uma vez (\textit{Exactly Once}), sem perdas, ou, duplicadas, via \textit{parallel recovery}, levando em consideração as observações já mencionadas \cite{Spark}.

No Storm, por outro lado, não há suporte ao modelo \textit{Exactly Once}, mas sim aos \textit{At Least Once} e \textit{At Most Once}. Em ordem, a primeira opção permite que o processamento seja realizado no mínimo uma vez, rastreando se o (a) evento (tupla) foi processado(a) ou não, através de seus \textit{IDs} e mensagens informando "\textit{ack}" (tupla processada), podendo haver duplicatas; o oposto ocorre na segunda alternativa, em que perdas são aceitas, processando os eventos no máximo uma vez \cite{Storm}. 

A proposta do Spark Streaming, nesse aspecto, é mais interessante para o processamento de \textit{stream} de \textit{tweets}, por garantir que a informação será processada uma única vez, através do modelo \textit{Exactly Once}.

\subsection{Escalabilidade}
\label{scalability}

Quanto ao requisito de escalabilidade, ambos suportam clusterização, portando são escaláveis horizontalmente, sendo o maior \textit{cluster} Spark conhecido composto por 8.000 nós \cite{Spark}. E, embora não tenham sido encontradas fontes confiáveis divulgando informações sobre o maior \textit{cluster} Storm existente, sabe­-se que ele é capaz de processar um milhão de mensagens com tamanho de 100 byte, por segundo e por nó \cite{Storm}.

\subsection{Modelo de programação}
\label{programmingModel}

Conforme exposto no Cap. \ref{chapter2}, no Spark os RDDs são conjuntos de dados que podem ser manipulados de forma distribuída, sendo possível realizar operações sob eles, gerando novos RDDs, através de transformações, ou, computando-os por meio das ações. O módulo Streaming, utiliza essa unidade como base da abstração DStream, conjunto de RDDs representando um \textit{stream}. Tais conceitos do modelo de programação do Spark podem ser mais difíceis de abstrair, tendo uma classificação de baixo nível, se comparados ao do Storm.

Por outro lado, numa perspectiva alto nível, o Storm propõe o conceito de Topologia, composta por \textit{bolts} e \textit{spouts}. Os \textit{spouts} são responsáveis pela entrada dos \textit{streams} (conjuntos de tuplas) da aplicação, processados posteriormente pelos \textit{bolts}. Devido a essas abstrações, consequentemente, pode haver maior facilidade em programar utilizando o Storm do que o Spark.